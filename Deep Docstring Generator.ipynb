{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNxDp3Me4zXx"
   },
   "source": [
    "\n",
    "# Deep Docstring Generation\n",
    "---\n",
    "\n",
    "This notebook describes, step by step, how we built our Deep Docstring Generator. The notebook is organized in different sections:\n",
    "\n",
    "\n",
    ">1. **Creation of the Dataset instance**, in order to properly manage the data. \n",
    ">2. **Creation and training** of the **Neural Machine Translation Model** with that training data.\n",
    ">3. Applying the trained model on **new (unseen) data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Greatest Common Divisor of a and b\n",
    "def get_GCD(a, b):    \n",
    "    while (b != 0):\n",
    "        if (a > b):\n",
    "            a -= b\n",
    "        else:\n",
    "            b -= a\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CaLEHfm244P5",
    "outputId": "3f21f707-94b0-4fa5-e5b5-e2239983fbca"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "n6RpYGOpibK5"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "-4NRRCudCCsR",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "47c37458-0982-45af-aa03-76ef744fd115",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processor\t: 0\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 60\n",
      "model name\t: Intel(R) Core(TM) i7-4790 CPU @ 3.60GHz\n",
      "stepping\t: 3\n",
      "microcode\t: 0xffffffff\n",
      "cpu MHz\t\t: 3591.689\n",
      "cache size\t: 8192 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 8\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 4\n",
      "apicid\t\t: 0\n",
      "initial apicid\t: 0\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti ssbd ibrs ibpb stibp fsgsbase bmi1 avx2 smep bmi2 erms invpcid xsaveopt flush_l1d arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit srbds\n",
      "bogomips\t: 7183.37\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 39 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 1\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 60\n",
      "model name\t: Intel(R) Core(TM) i7-4790 CPU @ 3.60GHz\n",
      "stepping\t: 3\n",
      "microcode\t: 0xffffffff\n",
      "cpu MHz\t\t: 3591.689\n",
      "cache size\t: 8192 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 8\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 4\n",
      "apicid\t\t: 1\n",
      "initial apicid\t: 1\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti ssbd ibrs ibpb stibp fsgsbase bmi1 avx2 smep bmi2 erms invpcid xsaveopt flush_l1d arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit srbds\n",
      "bogomips\t: 7183.37\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 39 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 2\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 60\n",
      "model name\t: Intel(R) Core(TM) i7-4790 CPU @ 3.60GHz\n",
      "stepping\t: 3\n",
      "microcode\t: 0xffffffff\n",
      "cpu MHz\t\t: 3591.689\n",
      "cache size\t: 8192 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 8\n",
      "core id\t\t: 1\n",
      "cpu cores\t: 4\n",
      "apicid\t\t: 2\n",
      "initial apicid\t: 2\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti ssbd ibrs ibpb stibp fsgsbase bmi1 avx2 smep bmi2 erms invpcid xsaveopt flush_l1d arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit srbds\n",
      "bogomips\t: 7183.37\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 39 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 3\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 60\n",
      "model name\t: Intel(R) Core(TM) i7-4790 CPU @ 3.60GHz\n",
      "stepping\t: 3\n",
      "microcode\t: 0xffffffff\n",
      "cpu MHz\t\t: 3591.689\n",
      "cache size\t: 8192 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 8\n",
      "core id\t\t: 1\n",
      "cpu cores\t: 4\n",
      "apicid\t\t: 3\n",
      "initial apicid\t: 3\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti ssbd ibrs ibpb stibp fsgsbase bmi1 avx2 smep bmi2 erms invpcid xsaveopt flush_l1d arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit srbds\n",
      "bogomips\t: 7183.37\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 39 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 4\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 60\n",
      "model name\t: Intel(R) Core(TM) i7-4790 CPU @ 3.60GHz\n",
      "stepping\t: 3\n",
      "microcode\t: 0xffffffff\n",
      "cpu MHz\t\t: 3591.689\n",
      "cache size\t: 8192 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 8\n",
      "core id\t\t: 2\n",
      "cpu cores\t: 4\n",
      "apicid\t\t: 4\n",
      "initial apicid\t: 4\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti ssbd ibrs ibpb stibp fsgsbase bmi1 avx2 smep bmi2 erms invpcid xsaveopt flush_l1d arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit srbds\n",
      "bogomips\t: 7183.37\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 39 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 5\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 60\n",
      "model name\t: Intel(R) Core(TM) i7-4790 CPU @ 3.60GHz\n",
      "stepping\t: 3\n",
      "microcode\t: 0xffffffff\n",
      "cpu MHz\t\t: 3591.689\n",
      "cache size\t: 8192 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 8\n",
      "core id\t\t: 2\n",
      "cpu cores\t: 4\n",
      "apicid\t\t: 5\n",
      "initial apicid\t: 5\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti ssbd ibrs ibpb stibp fsgsbase bmi1 avx2 smep bmi2 erms invpcid xsaveopt flush_l1d arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit srbds\n",
      "bogomips\t: 7183.37\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 39 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 6\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 60\n",
      "model name\t: Intel(R) Core(TM) i7-4790 CPU @ 3.60GHz\n",
      "stepping\t: 3\n",
      "microcode\t: 0xffffffff\n",
      "cpu MHz\t\t: 3591.689\n",
      "cache size\t: 8192 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 8\n",
      "core id\t\t: 3\n",
      "cpu cores\t: 4\n",
      "apicid\t\t: 6\n",
      "initial apicid\t: 6\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti ssbd ibrs ibpb stibp fsgsbase bmi1 avx2 smep bmi2 erms invpcid xsaveopt flush_l1d arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit srbds\n",
      "bogomips\t: 7183.37\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 39 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 7\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 60\n",
      "model name\t: Intel(R) Core(TM) i7-4790 CPU @ 3.60GHz\n",
      "stepping\t: 3\n",
      "microcode\t: 0xffffffff\n",
      "cpu MHz\t\t: 3591.689\n",
      "cache size\t: 8192 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 8\n",
      "core id\t\t: 3\n",
      "cpu cores\t: 4\n",
      "apicid\t\t: 7\n",
      "initial apicid\t: 7\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti ssbd ibrs ibpb stibp fsgsbase bmi1 avx2 smep bmi2 erms invpcid xsaveopt flush_l1d arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit srbds\n",
      "bogomips\t: 7183.37\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 39 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "egprMcTp8fLC"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Pkl6pHqucCk",
    "outputId": "1417b199-7a8e-4ad5-c730-fae4e239845c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "# %tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 491
    },
    "collapsed": true,
    "id": "uXTvSSrudg5Y",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "c16a3fb6-a1f1-4b3e-d118-acfb1622d34e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/MarcBS/keras.git\n",
      "  Cloning https://github.com/MarcBS/keras.git to /tmp/pip-req-build-umv18u3k\n",
      "  Running command git clone -q https://github.com/MarcBS/keras.git /tmp/pip-req-build-umv18u3k\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from Keras==2.3.1.1) (1.19.2)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from Keras==2.3.1.1) (1.6.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from Keras==2.3.1.1) (1.15.0)\n",
      "Requirement already satisfied: pyyaml in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from Keras==2.3.1.1) (5.4.1)\n",
      "Requirement already satisfied: h5py in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from Keras==2.3.1.1) (2.10.0)\n",
      "Requirement already satisfied: keras_applications>=1.0.6 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from Keras==2.3.1.1) (1.0.8)\n",
      "Requirement already satisfied: keras_preprocessing>=1.0.5 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from Keras==2.3.1.1) (1.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install git+https://github.com/MarcBS/keras.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "id": "0mtJWLes5JO7",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'nmt-keras' already exists and is not an empty directory.\n",
      "Found existing installation: Keras 2.3.1.1\n",
      "Uninstalling Keras-2.3.1.1:\n",
      "  Successfully uninstalled Keras-2.3.1.1\n",
      "Obtaining file:///mnt/c/Users/sagun/Downloads/ComGen/nmt-keras\n",
      "Collecting keras@ https://github.com/MarcBS/keras/archive/master.zip\n",
      "  Using cached https://github.com/MarcBS/keras/archive/master.zip\n",
      "Requirement already satisfied: cloudpickle in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from nmt-keras==0.6) (1.6.0)\n",
      "Requirement already satisfied: future in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from nmt-keras==0.6) (0.18.2)\n",
      "Requirement already satisfied: keras_applications in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from nmt-keras==0.6) (1.0.8)\n",
      "Requirement already satisfied: keras_preprocessing in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from nmt-keras==0.6) (1.1.2)\n",
      "Requirement already satisfied: h5py in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from nmt-keras==0.6) (2.10.0)\n",
      "Requirement already satisfied: matplotlib in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from nmt-keras==0.6) (3.4.1)\n",
      "Requirement already satisfied: multimodal-keras-wrapper in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from nmt-keras==0.6) (3.1.6)\n",
      "Requirement already satisfied: numpy in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from nmt-keras==0.6) (1.19.2)\n",
      "Requirement already satisfied: scikit-image in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from nmt-keras==0.6) (0.18.1)\n",
      "Requirement already satisfied: scikit-learn in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from nmt-keras==0.6) (0.24.1)\n",
      "Requirement already satisfied: six in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from nmt-keras==0.6) (1.15.0)\n",
      "Requirement already satisfied: tables in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from nmt-keras==0.6) (3.6.1)\n",
      "Requirement already satisfied: pandas in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from nmt-keras==0.6) (1.2.4)\n",
      "Requirement already satisfied: sacrebleu in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from nmt-keras==0.6) (1.5.1)\n",
      "Requirement already satisfied: sacremoses in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from nmt-keras==0.6) (0.0.44)\n",
      "Requirement already satisfied: scipy in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from nmt-keras==0.6) (1.6.2)\n",
      "Requirement already satisfied: tensorflow<2 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from nmt-keras==0.6) (1.15.0)\n",
      "Requirement already satisfied: pyyaml in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from keras@ https://github.com/MarcBS/keras/archive/master.zip->nmt-keras==0.6) (5.4.1)\n",
      "Requirement already satisfied: gast==0.2.2 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from tensorflow<2->nmt-keras==0.6) (0.2.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from tensorflow<2->nmt-keras==0.6) (3.14.0)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from tensorflow<2->nmt-keras==0.6) (1.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from tensorflow<2->nmt-keras==0.6) (1.12.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from tensorflow<2->nmt-keras==0.6) (0.36.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from tensorflow<2->nmt-keras==0.6) (3.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from tensorflow<2->nmt-keras==0.6) (1.36.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from tensorflow<2->nmt-keras==0.6) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from tensorflow<2->nmt-keras==0.6) (0.12.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from tensorflow<2->nmt-keras==0.6) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from tensorflow<2->nmt-keras==0.6) (1.15.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from tensorflow<2->nmt-keras==0.6) (0.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2->nmt-keras==0.6) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2->nmt-keras==0.6) (52.0.0.post20210125)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2->nmt-keras==0.6) (0.16.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2->nmt-keras==0.6) (3.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2->nmt-keras==0.6) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2->nmt-keras==0.6) (3.7.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from matplotlib->nmt-keras==0.6) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from matplotlib->nmt-keras==0.6) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from matplotlib->nmt-keras==0.6) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from matplotlib->nmt-keras==0.6) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from matplotlib->nmt-keras==0.6) (8.2.0)\n",
      "Requirement already satisfied: cython in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from multimodal-keras-wrapper->nmt-keras==0.6) (0.29.23)\n",
      "Requirement already satisfied: sklearn in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from multimodal-keras-wrapper->nmt-keras==0.6) (0.0)\n",
      "Requirement already satisfied: toolz in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from multimodal-keras-wrapper->nmt-keras==0.6) (0.11.1)\n",
      "Requirement already satisfied: subword-nmt in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from multimodal-keras-wrapper->nmt-keras==0.6) (0.3.7)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from pandas->nmt-keras==0.6) (2021.1)\n",
      "Requirement already satisfied: portalocker==2.0.0 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from sacrebleu->nmt-keras==0.6) (2.0.0)\n",
      "Requirement already satisfied: joblib in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from sacremoses->nmt-keras==0.6) (1.0.1)\n",
      "Requirement already satisfied: regex in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from sacremoses->nmt-keras==0.6) (2021.4.4)\n",
      "Requirement already satisfied: click in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from sacremoses->nmt-keras==0.6) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from sacremoses->nmt-keras==0.6) (4.60.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from scikit-image->nmt-keras==0.6) (2021.4.8)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from scikit-image->nmt-keras==0.6) (2.9.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from scikit-image->nmt-keras==0.6) (2.5.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from scikit-image->nmt-keras==0.6) (1.1.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->nmt-keras==0.6) (4.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from scikit-learn->nmt-keras==0.6) (2.1.0)\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (from tables->nmt-keras==0.6) (2.7.3)\n",
      "Building wheels for collected packages: keras\n",
      "  Building wheel for keras (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras: filename=Keras-2.3.1.1-py3-none-any.whl size=487500 sha256=8aa0b895eacdf012df3bc9d8bc4a458003e516868d12b2562315d441dfe8cafd\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-6z0d1nx7/wheels/68/86/9b/290dd8e0919a4070424e29c34886fbcf85d437c53506723c08\n",
      "Successfully built keras\n",
      "Installing collected packages: keras, nmt-keras\n",
      "  Attempting uninstall: nmt-keras\n",
      "    Found existing installation: nmt-keras 0.6\n",
      "    Uninstalling nmt-keras-0.6:\n",
      "      Successfully uninstalled nmt-keras-0.6\n",
      "  Running setup.py develop for nmt-keras\n",
      "Successfully installed keras-2.3.1.1 nmt-keras\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"./\")\n",
    "!git clone https://github.com/lvapeab/nmt-keras\n",
    "!pip3 uninstall -y keras\n",
    "os.chdir('nmt-keras')\n",
    "!pip3 install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jcuhzRGV8q56"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sNQVh7zrhsxT",
    "outputId": "18914ee5-4373-41c8-ff3a-b024c7067863"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lQIo-qo8yjF3"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AzHw6ks17z3R",
    "outputId": "9ca48af7-e757-479d-b6e1-348a47c2b3d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2.3.1\n",
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "!python3 -c \"import keras; print(keras.__version__)\"\n",
    "!python3 -c \"import tensorflow; print(tensorflow.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wybzPN14qA1V",
    "outputId": "642ad66e-c218-4c78-b4da-9a5862b21ef6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B6bRna4hv2XF",
    "outputId": "00b8ed9f-bcb9-41e5-b9b3-3a7f64664a3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: more-itertools in /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages (8.7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install more-itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSSh7bps4y1U"
   },
   "source": [
    "## 1. Building a Dataset model\n",
    "First, we are creating a [Dataset](https://github.com/MarcBS/multimodal_keras_wrapper/keras_wrapper/dataset.py) object (from the [Multimodal Keras Wrapper](https://github.com/MarcBS/multimodal_keras_wrapper) library). This object will be the interface between our data (text files) and the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hiY2fUFU83Rx"
   },
   "outputs": [],
   "source": [
    "from keras_wrapper.dataset import Dataset, saveDataset\n",
    "from data_engine.prepare_data import keep_n_captions\n",
    "dataset = Dataset('tutorial_dataset', 'tutorial', silence=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ify05BL8_Rj"
   },
   "source": [
    "Now that we have the empty dataset, we must indicate its inputs and outputs. In our case, we'll have two different inputs and one single output:\n",
    "\n",
    "1. Outputs:\n",
    "**target_text**: Sentences in our target language.\n",
    "\n",
    "2. Inputs:\n",
    "**source_text**: Sentences in the source language.\n",
    "\n",
    "**state_below**: Sentences in the target language, but shifted one position to the right (for teacher-forcing training of the model).\n",
    "\n",
    "For setting up the outputs, we use the setOutputs function, with the appropriate parameters. Note that, when we are building the dataset for the training split, we build the vocabulary (up to 30000 words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "c_L1RQUYA3Fs"
   },
   "outputs": [],
   "source": [
    "working_dir = \"./\"\n",
    "os.chdir(working_dir)\n",
    "file_path = working_dir + \"alldata-allfields-withtypes-parens-uniques.csv\"\n",
    "docstring_header = \"docstring\"\n",
    "ast_header = \"ast\"\n",
    "start_word = \"<start>\"  # start token\n",
    "end_word = \"<end>\"  # end token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5dl9l1nkXu4H"
   },
   "outputs": [],
   "source": [
    "n_parallel_loaders = 3\n",
    "beam_size = 6 if tf.test.is_gpu_available() else 1\n",
    "# beam_size = 3 if tf.test.is_gpu_available() else 1\n",
    "# tokenize_y = \"tokenize_montreal\"\n",
    "# tokenize_x = \"tokenize_soft\"\n",
    "batch_size = 72 #200 #230 #72 #280 #140 #230\n",
    "tokenize_y = \"tokenize_none\"\n",
    "tokenize_x = \"tokenize_none\"\n",
    "# tokenize_y = \"tokenize_soft\"\n",
    "# tokenize_x = \"tokenize_soft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Rhh1zmMC3QUc"
   },
   "outputs": [],
   "source": [
    "# The dataset is already cleaned, so need to run this cell\n",
    "\n",
    "# # from more_itertools import unique_everseen\n",
    "\n",
    "# open(file_path, 'w').close()\n",
    "# # with open(file_path_raw,'r') as in_file, open(file_path,'a+') as out_file:\n",
    "# #     out_file.writelines(unique_everseen(in_file))\n",
    "# with open(file_path_raw,'r') as in_file, open(file_path,'a+') as out_file:    \n",
    "#   seen = set() # set for fast O(1) amortized lookup\n",
    "#   for line in in_file:\n",
    "#       if line in seen: continue # skip duplicate\n",
    "#       seen.add(line)\n",
    "#       out_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "QMujB69V87nB"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "def create_dataset(path_to_file, num_examples=None):\n",
    "\n",
    "    iterations = 0\n",
    "    docstring_data, ast_data = [], []\n",
    "    d_lens, a_lens = [], []\n",
    "    d_lens_filtered, a_lens_filtered = [], []\n",
    "    print(path_to_file,num_examples)\n",
    "\n",
    "    def preprocesser_d(x):\n",
    "      x = x.replace('\\n', ' ').strip().lower()\n",
    "      x = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', x) #remove various punctuations\n",
    "      x = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', ' ', x) #remove url\n",
    "      return x\n",
    "\n",
    "    preprocesser_a = lambda x: x.replace(' \\n', ' ').strip().lower()\n",
    "\n",
    "    try:\n",
    "        with open(path_to_file,\"r\") as dataset:\n",
    "            reader = csv.DictReader((line.replace('\\0','') for line in dataset))\n",
    "            for row in reader:\n",
    "\n",
    "                if num_examples and iterations == num_examples:\n",
    "                  break\n",
    "\n",
    "                rdh = row[docstring_header]\n",
    "                rah = row[ast_header]\n",
    "                if rdh and rah:\n",
    "                  d_words = preprocesser_d(rdh)\n",
    "                  d_words_split = [word for word in d_words.split() if word]\n",
    "                  d_words = ' '.join(d_words_split)\n",
    "                  d_words_len = len(d_words_split)\n",
    "\n",
    "                  a_words = preprocesser_a(rah)\n",
    "                  a_words_split = [a for a in a_words.split() if a and a not in ('(',')')]\n",
    "                  a_words = ' '.join(a_words_split)\n",
    "                  a_words_len = len(a_words_split)\n",
    "\n",
    "                  d_lens.append(d_words_len)\n",
    "                  a_lens.append(a_words_len)\n",
    "\n",
    "                  # if 20 <= a_words_len <= 100 and d_words_len >= 2:\n",
    "                  if 25 <= a_words_len and d_words_len >= 2:\n",
    "                    # docstring_data.append(f\"{start_word} {d_words} {end_word}\\n\")\n",
    "                    docstring_data.append(f\"{d_words}\\n\")\n",
    "                    ast_data.append(f\"{a_words}\\n\")\n",
    "                    d_lens_filtered.append(d_words_len)\n",
    "                    a_lens_filtered.append(a_words_len)\n",
    "                    iterations += 1\n",
    "        \n",
    "        indices = set()\n",
    "        # if num_examples:\n",
    "        #   indices = set(random.sample(range(iterations), num_examples))\n",
    "        #   ast_data = [ast_data[i] for i in range(len(ast_data)) if i in indices]\n",
    "        #   a_lens_filtered = [len(s) for s in ast_data]\n",
    "        #   docstring_data = [docstring_data[i] for i in range(len(docstring_data)) if i in indices]\n",
    "        #   d_lens_filtered = [len(s) for s in docstring_data]\n",
    "\n",
    "        print(\"Finished reading dataset\")\n",
    "        print(\"d_lens max & avg\",max(d_lens),sum(d_lens)/len(d_lens))\n",
    "        print(\"d_lens_f max & avg\",max(d_lens_filtered),sum(d_lens_filtered)/len(d_lens_filtered))\n",
    "        print(\"a_lens max & avg\",max(a_lens),sum(a_lens)/len(a_lens))\n",
    "        print(\"a_lens_f max & avg\",max(a_lens_filtered),sum(a_lens_filtered)/len(a_lens_filtered))\n",
    "\n",
    "        return ast_data, docstring_data, a_lens, d_lens, a_lens_filtered, d_lens_filtered, indices if len(indices) else set()\n",
    "    except Exception as e:\n",
    "        print('Error loading dataset', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NO_45J7Q9I-x",
    "outputId": "56b8a0c5-df97-4fc5-c505-a35c8a872a60",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./alldata-allfields-withtypes-parens-uniques.csv 25000\n",
      "Finished reading dataset\n",
      "d_lens max & avg 1508 24.50902450159793\n",
      "d_lens_f max & avg 1508 27.9506\n",
      "a_lens max & avg 8176 113.89706285192513\n",
      "a_lens_f max & avg 8176 143.62556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20250, 2250, 2500, 20250, 2250, 2500)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_examples = 25000 #10000 #None #5000\n",
    "x, y, x_lens, y_lens, x_lens_f, y_lens_f, indices = create_dataset(file_path, num_examples)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1)\n",
    "len(x_train),len(x_val),len(x_test),len(y_train),len(y_val),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "zlEGNmYO06S9",
    "outputId": "d98d373e-7bad-4957-e6da-87b9dd9665e9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np    \n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(x_lens, bins=np.arange(0,500,15),log=True,label=\"original\")\n",
    "plt.hist(x_lens_f, bins=np.arange(0,500,15),log=True,label=\"filter\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "UAUtsNmX1YDd",
    "outputId": "a95feb33-8647-470f-c07a-7b30c0ee2de5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np    \n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_lens, bins=np.arange(0,250,5),log=True,label=\"original\")\n",
    "plt.hist(y_lens_f, bins=np.arange(0,250,5),log=True,label=\"filter\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Zqji6-0e196f",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "2c5a8025-050b-4223-b3a2-a4a6d5ad0735",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['functiondef args3 arguments arg arg arg constant str assign name store args1 name load int assign name store args3 name load name load name load args0 attribute name load load assign name store list load assign name store args1 attribute name load load int for name store args1 name load args0 attribute name load load assign name store args1 attribute name load load name load assign name store args2 name load subscript name load index int load subscript name load index int load call args1 attribute name load load name load assign name store args1 attribute name load load list name load load call args1 attribute name load load name load return name load\\n',\n",
       " 'functiondef args2 arguments arg arg constant str if compare name load is nonetype return bool assign name store args1 attribute name load load name load if args1 attribute name load load name load assign subscript name load index name load store name load return bool return bool name load\\n',\n",
       " 'functiondef args1 arguments arg constant str call args0 attribute args2 name load name load name load load call args2 attribute attribute name load load load str int\\n',\n",
       " 'functiondef args2 arguments arg arg name load constant str try assign name store args0 attribute args1 attribute name load load list str str attribute name load load name load attribute name load load load load return args1 attribute attribute name load load load subscript name load index unaryop usub int load excepthandler attribute name load load return str name load\\n',\n",
       " 'functiondef arguments constant str assign name store int assign name store int assign name store args1 attribute name load load list name load name load name load load with withitem args1 name load name load assign name store args1 attribute attribute name load load load tuple name load int load assign name store int assign name store args3 attribute name load load unaryop usub int unaryop usub int int assign name store args2 name load name load name load keyword name load keyword name load assign name store args3 attribute name load load float float int assign name store args2 name load name load name load keyword name load keyword name load\\n',\n",
       " 'functiondef args2 arguments arg arg constant str call args1 attribute name load load str keyword bool assign name store args2 attribute attribute name load load load str args2 attribute name load load str str with withitem args2 name load name load str name store call args1 attribute name load load name load\\n',\n",
       " 'functiondef arguments constant str if compare attribute name load load eq str try assign name store args1 name load subscript attribute name load load index str load excepthandler tuple name load name load load assign name store int if compare attribute name load load eq str try assign name store args1 name load args0 attribute args1 attribute name load load str load excepthandler name load assign name store int try assign name store args1 attribute name load load str excepthandler tuple name load name load name load load assign name store int if compare name load gte int return name load raise args1 name load str\\n',\n",
       " 'functiondef args6 arguments arg arg arg arg arg arg nonetype nonetype nonetype nonetype nonetype constant str assign attribute name load store nonetype assign attribute name load store nonetype assign attribute name load store nonetype assign attribute name load store nonetype assign attribute name load store nonetype assign attribute name load store nonetype if compare name load isnot nonetype assign attribute name load store name load if compare name load isnot nonetype assign attribute name load store name load if compare name load isnot nonetype assign attribute name load store name load assign attribute name load store name load if compare name load isnot nonetype assign attribute name load store name load\\n',\n",
       " 'functiondef args2 arguments arg arg constant str if args2 name load name load attribute attribute attribute attribute name load load load load load return bool if args2 name load name load name load return bool return bool\\n',\n",
       " 'functiondef args6 arguments arg arg arg arg arg arg int int nonetype attribute name load load constant str if compare name load is nonetype assign name store attribute name load load assign name store unaryop usub int try assign tuple name store name store store args6 attribute name load load args1 name load attribute name load load name load name load name load name load args1 name load binop name load mult int excepthandler name load assign name store args1 name load name load return name load\\n',\n",
       " 'functiondef args2 arguments arg arg name load constant str with withitem args1 attribute name load load str assign name store args1 attribute attribute name load load load attribute name load load assign name store binop name load sub name load if compare args0 attribute name load load lt float assign tuple name store name store store tuple name load name load load return tuple name load name load load subscript name load index tuple name load name load load load\\n',\n",
       " 'functiondef args2 arguments arg arg constant str call args3 attribute args2 name load name load name load load str name load name load assign attribute name load store name load\\n',\n",
       " 'functiondef args1 arguments arg constant str if compare attribute name load load eq int assign name store attribute attribute name load load load if compare name load isnot nonetype for name store args1 attribute attribute attribute name load load load load name load assign name store args4 attribute name load load attribute attribute name load load load args1 name load name load args0 attribute name load load name load call args1 attribute attribute attribute name load load load load name load if compare attribute name load load eq int assign name store attribute attribute name load load load if compare name load isnot nonetype assign name store args4 attribute name load load attribute attribute name load load load args1 name load name load args0 attribute name load load name load call args1 attribute attribute attribute name load load load load name load assign attribute name load store bool nonetype\\n',\n",
       " 'functiondef arguments constant str return dict str str str str str str str str str str str str str str str str tuple attribute name load load load tuple name load load tuple name load load tuple attribute name load load load tuple name load load tuple name load load tuple name load load tuple name load load tuple name load load tuple name load load tuple name load load tuple name load load tuple name load load tuple name load load tuple name load load tuple name load load name load\\n',\n",
       " 'functiondef args1 arguments arg constant str assign name store args1 attribute name load load tuple int int load keyword name load assign name store args1 attribute name load load name load call args1 attribute name load load args1 attribute name load load compare name load eq int\\n',\n",
       " 'functiondef args3 arguments arg arg arg constant str if unaryop not name load return assign name store args1 name load name load if compare attribute name load load lt name load raise args1 name load binop str mod tuple attribute name load load name load load assign name store subscript attribute name load load slice unaryop usub name load load for tuple name store name store store args2 name load name load name load if compare name load in name load if compare name load noteq subscript name load index name load load raise args1 name load binop str mod tuple name load name load subscript name load index name load load load assign subscript name load index name load store name load\\n',\n",
       " 'functiondef args3 arguments arg arg arg bool bool constant str assign name store list load assign name store args6 attribute args2 attribute args0 attribute args1 attribute attribute name load load load args0 attribute attribute name load load load load keyword name load load name load name load load attribute name load load attribute name load load attribute name load load attribute name load load attribute name load load attribute name load load if name load assign name store args1 attribute name load load compare attribute name load load eq str if boolop and unaryop not name load unaryop not name load assign name store args1 attribute name load load compare attribute name load load noteq str for name store args0 attribute name load load assign tuple name store name store name store name store name store name store name store store name load assign name store args0 attribute name load load assign subscript name load index str store dict str str str str name load name load name load args1 name load attribute name load load assign subscript name load index str store dict str str str str name load name load name load args1 name load attribute name load load assign subscript name load index str store list load for name store attribute name load load call args1 attribute subscript name load index str load load args1 name load attribute name load load if compare attribute name load load isnot nonetype assign name store args1 attribute name load load attribute name load load assign subscript name load index str store list dict str str str str args1 name load attribute name load load subscript name load index str load subscript name load index str load subscript name load index str load load assign subscript name load index str store list load assign name store args1 name load attribute name load load keyword lambda arguments arg attribute name load load for name store name load call args1 attribute subscript name load index str load load dict str str str str args1 name load attribute name load load attribute name load load attribute name load load attribute name load load assign subscript name load index str store list load for name store attribute name load load call args1 attribute subscript name load index str load load dict str str str str args1 name load attribute name load load attribute name load load attribute name load load attribute name load load call args1 attribute name load load name load return name load\\n',\n",
       " 'functiondef args2 arguments arg arg constant str if args1 attribute name load load str call args1 attribute attribute name load load load name load if args1 attribute name load load str call args1 attribute attribute name load load load name load if args1 attribute name load load str call args1 attribute attribute name load load load name load\\n',\n",
       " 'functiondef args2 arguments arg arg constant str assign name store subscript args1 attribute attribute name load load load name load index int load assign attribute name load store args1 attribute attribute name load load load name load call args1 attribute attribute attribute name load load load load name load call args1 attribute attribute attribute name load load load load attribute name load load args1 name load str\\n',\n",
       " 'functiondef arguments constant str return dict attribute name load load attribute name load load dict str str args1 name load str args1 name load str dict str str args1 name load str args1 name load str\\n',\n",
       " 'functiondef args3 arguments arg arg arg constant str assign tuple name store name store store args2 name load name load name load return args2 attribute name load load name load name load name load\\n',\n",
       " 'functiondef args1 arguments arg constant str call args1 name load args1 attribute name load load list unaryop usub float float float unaryop usub attribute name load load attribute name load load attribute name load load load name load\\n',\n",
       " 'functiondef args8 arguments arg arg arg arg arg arg arg arg constant str assign name store attribute subscript name load index args0 attribute name load load load load assign name store args1 name load name load assign name store binop name load add name load assign subscript name load index args0 attribute name load load store tuple name load name load load call args3 name load name load args0 attribute name load load name load if unaryop not name load assign subscript name load index args0 attribute name load load store args1 attribute name load load list load keyword attribute name load load assign subscript subscript name load index args0 attribute name load load load index name load store binop args1 attribute name load load name load add name load assign subscript name load index args0 attribute name load load store unaryop usub args1 attribute name load load binop args0 attribute name load load add int keyword attribute name load load assign subscript subscript name load index args0 attribute name load load load index name load store binop args1 attribute name load load name load add name load return tuple name load binop name load add int load name load\\n',\n",
       " 'functiondef arguments constant str assign name store args2 attribute attribute name load load load args1 attribute attribute name load load load name load str assign name store args0 attribute attribute name load load load keyword binop name load add str assign name store args0 attribute name load load keyword binop name load add str return tuple name load name load load attribute name load load\\n',\n",
       " 'functiondef args1 arguments arg arg arg constant str if unaryop not name load raise args1 name load str assign name store args1 attribute attribute name load load load name load if name load return name load if unaryop not attribute name load load assign attribute name load store args0 name load if unaryop not attribute name load load raise args0 name load keyword str assign name store args2 attribute attribute name load load load name load attribute name load load keyword name load return name load\\n']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LccQyzR96rYY",
    "outputId": "79200559-2950-438e-cbd5-210becf0f45d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reprojects the bounding box crssrc source crs ogrpoly ogr polygon\\n',\n",
       " 'fallback imputation for shapes use the default symbol usually the last symbol in the list bool true if there was any missing data\\n',\n",
       " 'before template render hook\\n',\n",
       " 'get a task state as a string\\n',\n",
       " 'verify that the upf raises no exceptions for several reasonable choices of rbins\\n',\n",
       " 'compose a name and write output file\\n',\n",
       " 'returns the number of cpus in the system borrowed from the python processing package\\n',\n",
       " 'activityrate a model defined in swagger\\n',\n",
       " 'validate a meta argument\\n',\n",
       " 'send a message to the control and wait for it to return or to timeout if no timeout is given then a default timeout of 01 of a second will be used\\n',\n",
       " 'secret share an abstracttensor secret abstracttensor the tensor to share a pair of abstracttensor the shares\\n',\n",
       " 'type driver class mesoshttp client mesosclient schedulerdriver\\n',\n",
       " 'creates player s based on the selected items and adds to the queue if the active menu is the feed menu then this will create players for all episodes in the selected feed if the active menu is the episode menu this will simply create a single player this method will not clear the queue prior to adding the new player s nor will it play the episodes after running\\n',\n",
       " 'and the value is attribute type\\n',\n",
       " 'a label matrix of all zeros has no hole\\n',\n",
       " 'incrementally check and update core dimension sizes for a single argument dim sizes dict str int sizes of existing core dimensions will be updated in place arg ndarray argument to examine core dims tuple str core dimensions for this argument\\n',\n",
       " 'return all comments related to given task\\n',\n",
       " 'handle new message\\n',\n",
       " 'set main program file and folder path\\n',\n",
       " 'sdd metadata that is passed through to the angular app see service delivery dashboard directive js for an example of using this\\n',\n",
       " 'construct a polynomial from an expression\\n',\n",
       " 'tests func colour models rgb transfer functions filmic pro log encoding filmicpro6 definition nan support\\n',\n",
       " 'function which creates node lookups param net the pandapipes network type net pandapipesnet param ft lookups type ft lookups param table lookup type table lookup param idx lookups type idx lookups param current start type current start param current table type current table param internal nodes lookup type internal nodes lookup rtype\\n',\n",
       " 'poisson equation with dirichlet conditions laplace u f in the interior u u d on the boundary u d 1 x 2 2y 2 f 4 linear system resulting from discretization on an elliptic grid\\n',\n",
       " 'request an access token for scopes note this method is called by azure sdk clients it isn t intended for use in application code when this method is called the credential will try to get the refresh token saved by vs code if a refresh token can be found it will redeem the refresh token for an access token and return the access token param str scopes desired scopes for the access token this method requires at least one scope rtype class azure core credentials accesstoken raises azure identity credentialunavailableerror fail to get refresh token\\n']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "88Zyigc7SLTb"
   },
   "outputs": [],
   "source": [
    "x_max_text_len = 300 #300 #140 #142 #142\n",
    "y_max_text_len = 10 #50 #30\n",
    "x_max_words = 200 #30000 #100 #15000 #31000 \n",
    "y_max_words = 30000 #20000 #14500 #20000 #26000 #35000 #33000\n",
    "y_min_occ = 0 #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24kYeauSQlAN",
    "outputId": "bf4ccc76-c861-44f4-d9b6-085f7dc1d922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250\n",
      "20250\n",
      "2250\n",
      "2250\n",
      "2500\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "open('x_train.txt', 'w').close()\n",
    "with open(os.path.join(working_dir, 'x_train.txt'), 'a+') as datafile:\n",
    "  datafile.writelines(x_train)\n",
    "  print(len(x_train))\n",
    "\n",
    "open('y_train.txt', 'w').close()\n",
    "with open(os.path.join(working_dir, 'y_train.txt'), 'a+') as datafile:\n",
    "  datafile.writelines(y_train)\n",
    "  print(len(y_train))\n",
    "\n",
    "open('x_val.txt', 'w').close()\n",
    "with open(os.path.join(working_dir, 'x_val.txt'), 'a+') as datafile:\n",
    "  datafile.writelines(x_val)\n",
    "  print(len(x_val))\n",
    "\n",
    "open('y_val.txt', 'w').close()\n",
    "with open(os.path.join(working_dir, 'y_val.txt'), 'a+') as datafile:\n",
    "  datafile.writelines(y_val)\n",
    "  print(len(y_val))\n",
    "\n",
    "open('x_test.txt', 'w').close()\n",
    "with open(os.path.join(working_dir, 'x_test.txt'), 'a+') as datafile:\n",
    "  datafile.writelines(x_test)\n",
    "  print(len(x_test))\n",
    "\n",
    "open('y_test.txt', 'w').close()\n",
    "with open(os.path.join(working_dir, 'y_test.txt'), 'a+') as datafile:\n",
    "  datafile.writelines(y_test)\n",
    "  print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "d1A8D0qn9IeE",
    "outputId": "e22900a3-7da0-4e2e-8844-6c86e15a69f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:32] \tApplying tokenization function: \"tokenize_none\".\n",
      "[16/04/2021 15:25:33] Creating vocabulary for data with data_id 'target_text'.\n",
      "[16/04/2021 15:25:33] \t Total: 24654 unique words in 20250 sentences with a total of 571261 words.\n",
      "[16/04/2021 15:25:33] Creating dictionary of 30000 most common words, covering 100.0% of the text.\n",
      "[16/04/2021 15:25:33] Loaded \"train\" set outputs of data_type \"text\" with data_id \"target_text\" and length 20250.\n",
      "[16/04/2021 15:25:33] \tApplying tokenization function: \"tokenize_none\".\n",
      "[16/04/2021 15:25:33] Loaded \"val\" set outputs of data_type \"text\" with data_id \"target_text\" and length 2250.\n"
     ]
    }
   ],
   "source": [
    "dataset.setOutput('y_train.txt',\n",
    "             'train',\n",
    "             type='text',\n",
    "             id='target_text',\n",
    "             tokenization=tokenize_y,\n",
    "             build_vocabulary=True,\n",
    "             pad_on_batch=True,\n",
    "             sample_weights=True,\n",
    "             max_text_len=y_max_text_len,\n",
    "             max_words=y_max_words,\n",
    "             min_occ=y_min_occ)\n",
    "\n",
    "dataset.setOutput('y_val.txt',\n",
    "             'val',\n",
    "             type='text',\n",
    "             id='target_text',\n",
    "             pad_on_batch=True,\n",
    "             tokenization=tokenize_y,\n",
    "             sample_weights=True,\n",
    "             max_text_len=y_max_text_len,\n",
    "             max_words=y_max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f72G9mHX9PPq",
    "outputId": "d498c3a8-c602-492d-c79d-34bb32679911"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:39] \tApplying tokenization function: \"tokenize_none\".\n",
      "[16/04/2021 15:25:40] Creating vocabulary for data with data_id 'source_text'.\n",
      "[16/04/2021 15:25:40] \t Total: 138 unique words in 20250 sentences with a total of 2892690 words.\n",
      "[16/04/2021 15:25:40] Creating dictionary of 200 most common words, covering 100.0% of the text.\n",
      "[16/04/2021 15:25:40] Loaded \"train\" set inputs of data_type \"text\" with data_id \"source_text\" and length 20250.\n",
      "[16/04/2021 15:25:41] \tApplying tokenization function: \"tokenize_none\".\n",
      "[16/04/2021 15:25:41] Loaded \"val\" set inputs of data_type \"text\" with data_id \"source_text\" and length 2250.\n"
     ]
    }
   ],
   "source": [
    "dataset.setInput('x_train.txt',\n",
    "            'train',\n",
    "            type='text',\n",
    "            id='source_text',\n",
    "            pad_on_batch=True,\n",
    "            tokenization=tokenize_x,\n",
    "            build_vocabulary=True,\n",
    "            fill='end',\n",
    "            max_text_len=x_max_text_len,\n",
    "            max_words=x_max_words,\n",
    "            min_occ=0)\n",
    "\n",
    "dataset.setInput('x_val.txt',\n",
    "            'val',\n",
    "            type='text',\n",
    "            id='source_text',\n",
    "            pad_on_batch=True,\n",
    "            tokenization=tokenize_x,\n",
    "            fill='end',\n",
    "            max_text_len=x_max_text_len,\n",
    "            min_occ=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jipVyl7f9NTz"
   },
   "source": [
    "Similarly, we introduce the source text data, with the setInputs function. Again, when building the training split, we must construct the vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHvZimmm9U0p"
   },
   "source": [
    "...and for the 'state_below' data. Note that: 1) The offset flat is set to 1, which means that the text will be shifted to the right 1 position. 2) During sampling time, we won't have this input. Hence, we 'hack' the dataset model by inserting an artificial input, of type 'ghost' for the validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YiTM3y449ZFL",
    "outputId": "0486008d-38f4-479e-f65d-71cd8f7f6340"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:43] \tApplying tokenization function: \"tokenize_none\".\n",
      "[16/04/2021 15:25:43] \tReusing vocabulary named \"target_text\" for data with data_id \"state_below\".\n",
      "[16/04/2021 15:25:43] Loaded \"train\" set inputs of data_type \"text\" with data_id \"state_below\" and length 20250.\n",
      "[16/04/2021 15:25:43] Loaded \"val\" set inputs of data_type \"ghost\" with data_id \"state_below\" and length 2250.\n"
     ]
    }
   ],
   "source": [
    "dataset.setInput('y_train.txt',\n",
    "            'train',\n",
    "            type='text',\n",
    "            id='state_below',\n",
    "            required=False,\n",
    "            tokenization=tokenize_y,\n",
    "            pad_on_batch=True,\n",
    "            build_vocabulary='target_text',\n",
    "            offset=1,\n",
    "            fill='end',\n",
    "            max_text_len=y_max_text_len,\n",
    "            max_words=y_max_words)\n",
    "dataset.setInput(None,\n",
    "            'val',\n",
    "            type='ghost',\n",
    "            id='state_below',\n",
    "            required=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9H-1qb1ksD5Y"
   },
   "source": [
    "We can also keep the literal source words (for replacing unknown words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "akyexhdu8kry",
    "outputId": "40cc5644-6392-4e8f-e111-f53f82285d62"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:43] Loaded \"train\" set inputs of type \"file-name\" with id \"raw_source_text\".\n",
      "[16/04/2021 15:25:43] Loaded \"val\" set inputs of type \"file-name\" with id \"raw_source_text\".\n"
     ]
    }
   ],
   "source": [
    "for split, input_text_filename in zip(['train', 'val'], ['x_train.txt','x_val.txt']):\n",
    "  dataset.setRawInput(input_text_filename,\n",
    "                split,\n",
    "                type='file-name',\n",
    "                id='raw_source_text',\n",
    "                overwrite_split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcYiuysd9cK4"
   },
   "source": [
    "We also need to match the references with the inputs. Since we only have one reference per input sample, we set `repeat=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1HQqnSwyi4Fs",
    "outputId": "cb307ca2-1da0-44bf-cf1d-e48e246c4f86"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:43] Keeping 1 captions per input on the val set.\n",
      "[16/04/2021 15:25:43] Samples reduced to 2250 in val set.\n"
     ]
    }
   ],
   "source": [
    "keep_n_captions(dataset, repeat=1, n=1, set_names=['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDYhlBpR9vgi"
   },
   "source": [
    "Finally, we can save our dataset instance for using in other experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YQ1VJhUg8fM6",
    "outputId": "b0ef48ce-c1f1-4c14-fb8d-1776f22adcfc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:43] <<< Saving Dataset instance to datasets/Dataset_tutorial_dataset.pkl ... >>>\n",
      "[16/04/2021 15:25:43] <<< Dataset instance saved >>>\n"
     ]
    }
   ],
   "source": [
    "saveDataset(dataset, 'datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yj8aYICU-eLH"
   },
   "source": [
    "## 2. Creating and training a Neural Translation Model\n",
    "Now, we'll create and train a Neural Machine Translation (NMT) model. Since there is a significant number of hyperparameters, we'll use the default ones, specified in the `config.py` file. Note that almost every hardcoded parameter is automatically set from config if we run  `main.py `.\n",
    "\n",
    "We'll create an `'AttentionRNNEncoderDecoder'` (a LSTM encoder-decoder with attention mechanism). Refer to the [`model_zoo.py`](https://github.com/lvapeab/nmt-keras/blob/master/nmt_keras/model_zoo.py) file for other models (e.g. Transformer). \n",
    "\n",
    "So first, let's import the model and the hyperparameters. We'll also load the dataset we stored in the previous section (not necessary as it is in memory, but as a demonstration):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TszghyVO_M0B",
    "outputId": "10e517ae-e01f-4ac0-81e7-a3c273c2913a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:43] <<< Cupy not available. Using numpy. >>>\n"
     ]
    }
   ],
   "source": [
    "os.chdir(working_dir)\n",
    "os.chdir('nmt-keras')\n",
    "\n",
    "from config import load_parameters\n",
    "from nmt_keras.model_zoo import TranslationModel\n",
    "from keras_wrapper.cnn_model import loadModel\n",
    "from keras_wrapper.dataset import loadDataset\n",
    "from keras_wrapper.extra.callbacks import PrintPerformanceMetricOnEpochEndOrEachNUpdates\n",
    "params = load_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:43] <<< Loading Dataset instance from datasets/Dataset_tutorial_dataset.pkl ... >>>\n",
      "[16/04/2021 15:25:44] <<< Dataset instance loaded >>>\n"
     ]
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "dataset = loadDataset('datasets/Dataset_tutorial_dataset.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MHVvMDYFmcQ"
   },
   "source": [
    "Since the number of words in the dataset may be unknown beforehand, we must update the params information according to the dataset instance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "BdnQBBs0kSJ2"
   },
   "outputs": [],
   "source": [
    "params['num_examples'] = num_examples\n",
    "params['y_max_text_len'] = y_max_text_len\n",
    "params['x_max_text_len'] = x_max_text_len\n",
    "params['tokenize_x'] = tokenize_x\n",
    "params['tokenize_y'] = tokenize_y\n",
    "params['x_max_words'] = x_max_words\n",
    "params['y_max_words'] = y_max_words\n",
    "params['y_min_occ'] = y_min_occ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "v-P-awcq_5qt"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "with open(f'indices-{datetime.datetime.now()}','a+') as indices_file:\n",
    "  indices_file.write(\",\".join([str(i) for i in list(indices)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "U3BeuRKiMV9D"
   },
   "outputs": [],
   "source": [
    "# Model choice\n",
    "\n",
    "\n",
    "#  Supported models: 'AttentionRNNEncoderDecoder' and 'Transformer'.\n",
    "params['MODEL_TYPE'] = 'AttentionRNNEncoderDecoder'\n",
    "# params['MODEL_TYPE'] = 'Transformer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "h7FIJGybFm7C"
   },
   "outputs": [],
   "source": [
    "params['INPUT_VOCABULARY_SIZE'] = dataset.vocabulary_len['source_text']\n",
    "params['OUTPUT_VOCABULARY_SIZE'] = dataset.vocabulary_len['target_text']\n",
    "is_transformer = params.get('ATTEND_ON_OUTPUT', 'transformer' in params['MODEL_TYPE'].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "821qCbNTvH67"
   },
   "outputs": [],
   "source": [
    "drop_p = 0.2 #0.2\n",
    "# if not is_transformer:\n",
    "#   params['RECURRENT_INPUT_DROPOUT_P'] = drop_p              \n",
    "#   params['RECURRENT_DROPOUT_P'] = drop_p\n",
    "# else:\n",
    "#   params['DROPOUT_P'] = drop_p\n",
    "\n",
    "params['ATTENTION_DROPOUT_P'] = drop_p\n",
    "params['DROPOUT_P'] = drop_p\n",
    "params['USE_BATCH_NORMALIZATION'] = not drop_p      \n",
    "\n",
    "\n",
    "params['USE_CUDNN'] = tf.test.is_gpu_available()\n",
    "params['N_GPUS'] = 1 if tf.test.is_gpu_available() else 0\n",
    "params['BEAM_SIZE'] = beam_size\n",
    "params['TOKENIZATION_METHOD'] = tokenize_x\n",
    "params['MAX_INPUT_TEXT_LEN'] = x_max_text_len\n",
    "params['MAX_OUTPUT_TEXT_LEN'] = y_max_text_len\n",
    "params['INPUT_VOCABULARY_SIZE'] = min(len(dataset.vocabulary['source_text']['idx2words']),x_max_words)\n",
    "params['OUTPUT_VOCABULARY_SIZE'] = min(len(dataset.vocabulary['target_text']['idx2words']),y_max_words)\n",
    "params['SRC_LAN'] = \"ast\"\n",
    "params['TRG_LAN'] = \"en\"\n",
    "params['MAXLEN_GIVEN_X'] = False\n",
    "params['MINLEN_GIVEN_X'] = False\n",
    "params['DATASET_NAME'] = 'ASTDocstring'\n",
    "\n",
    "params['TASK_NAME'] = params['DATASET_NAME']\n",
    "params['DATA_ROOT_PATH'] = \"\"\n",
    "params['PATIENCE'] = 3\n",
    "params['PLOT_EVALUATION'] = True\n",
    "params['LABEL_SMOOTHING'] = 0.1\n",
    "\n",
    "params['KERAS_METRICS'] = ['perplexity'] \n",
    "params['EVAL_ON_SETS'] = ['train','val']\n",
    "params['EPOCHS_FOR_SAVE'] = 5\n",
    "\n",
    "if not is_transformer:\n",
    "  params['BATCH_SIZE'] = batch_size\n",
    "  size_num = 512\n",
    "  params['SOURCE_TEXT_EMBEDDING_SIZE'] = size_num #64\n",
    "  params['TARGET_TEXT_EMBEDDING_SIZE'] = size_num #//4 #64\n",
    "  params['ENCODER_HIDDEN_SIZE'] = size_num #64\n",
    "  params['DECODER_HIDDEN_SIZE'] = size_num #64\n",
    "  params['ATTENTION_SIZE'] = params['DECODER_HIDDEN_SIZE']\n",
    "  n_layers = 2\n",
    "  params['N_LAYERS_ENCODER'] = n_layers\n",
    "  params['N_LAYERS_DECODER'] = n_layers\n",
    "  params['SKIP_VECTORS_HIDDEN_SIZE'] = params['TARGET_TEXT_EMBEDDING_SIZE']\n",
    "  params['DEEP_OUTPUT_LAYERS'] = [('linear', size_num)] #64)]\n",
    "  params['MODEL_SIZE'] = size_num #64\n",
    "else:\n",
    "  params['BATCH_SIZE'] = batch_size\n",
    "  size_num = 512\n",
    "  params['SOURCE_TEXT_EMBEDDING_SIZE'] = size_num #64\n",
    "  params['TARGET_TEXT_EMBEDDING_SIZE'] = size_num\n",
    "  params['ENCODER_HIDDEN_SIZE'] = size_num #64\n",
    "  params['DECODER_HIDDEN_SIZE'] = size_num #64\n",
    "  params['ATTENTION_SIZE'] = params['DECODER_HIDDEN_SIZE']\n",
    "  params['N_HEADS'] = 4\n",
    "  n_layers = 3\n",
    "  params['N_LAYERS_ENCODER'] = n_layers\n",
    "  params['N_LAYERS_DECODER'] = n_layers\n",
    "  params['SKIP_VECTORS_HIDDEN_SIZE'] = params['TARGET_TEXT_EMBEDDING_SIZE']\n",
    "  params['DEEP_OUTPUT_LAYERS'] = [('linear', size_num)] #64)]\n",
    "  params['MODEL_SIZE'] = size_num #64\n",
    "  # params['ATTENTION_MODE'] = 'dot'\n",
    "\n",
    "# params['NORMALIZE_SAMPLING'] = True\n",
    "# params['SEARCH_PRUNING'] = True\n",
    "params['LENGTH_PENALTY'] = True\n",
    "params['COVERAGE_PENALTY'] = True\n",
    "\n",
    "params['OPTIMIZER'] = 'Adam'\n",
    "if params['OPTIMIZER'] == 'SGD':\n",
    "  params['LR'] = 0.01\n",
    "  params['LR_REDUCE_EACH_EPOCHS'] = True\n",
    "  params['LR_DECAY'] = 1\n",
    "elif params['OPTIMIZER'] == 'Adam':\n",
    "  params['LR'] = 0.0002 #0.001\n",
    "#NOTE: model_size must == embed_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Vrn6DXm60d7C"
   },
   "outputs": [],
   "source": [
    "def set_model_name(params):\n",
    "  if params['MODEL_TYPE'] == 'AttentionRNNEncoderDecoder':\n",
    "    return params['TASK_NAME'] + '_' + params['SRC_LAN'] + params['TRG_LAN'] + '_' + params['MODEL_TYPE'] + \\\n",
    "      '_src_emb_' + str(params['SOURCE_TEXT_EMBEDDING_SIZE']) + \\\n",
    "      '_bidir_' + str(params['BIDIRECTIONAL_ENCODER']) + \\\n",
    "      '_enc_' + params['ENCODER_RNN_TYPE'] + '_' + str(params['ENCODER_HIDDEN_SIZE']) + \\\n",
    "      '_dec_' + params['DECODER_RNN_TYPE'] + '_' + str(params['DECODER_HIDDEN_SIZE']) + \\\n",
    "      '_deepout_' + '_'.join([layer[0] for layer in params['DEEP_OUTPUT_LAYERS']]) + \\\n",
    "      '_trg_emb_' + str(params['TARGET_TEXT_EMBEDDING_SIZE']) + \\\n",
    "      '_' + params['OPTIMIZER'] + '_' + str(params['LR'])\n",
    "  elif params['MODEL_NAME'] == 'Transformer':\n",
    "    return params['TASK_NAME'] + '_' + params['SRC_LAN'] + params['TRG_LAN'] + '_' + params['MODEL_TYPE'] + \\\n",
    "              '_model_size_' + str( params['MODEL_SIZE']) + \\\n",
    "              '_ff_size_' + str( params['FF_SIZE']) + \\\n",
    "              '_num_heads_' + str( params['N_HEADS']) + \\\n",
    "              '_encoder_blocks_' + str( params['N_LAYERS_ENCODER']) + \\\n",
    "              '_decoder_blocks_' + str( params['N_LAYERS_DECODER']) + \\\n",
    "              '_deepout_' + '_'.join([layer[0] for layer in params['DEEP_OUTPUT_LAYERS']]) + \\\n",
    "              '_' +  params['OPTIMIZER'] + '_' + str(params['LR'])\n",
    "  else:\n",
    "    return params['TASK_NAME'] + '_' + params['SRC_LAN'] + params['TRG_LAN'] + '_' +\\\n",
    "                  params['MODEL_TYPE']  + '_' + params['OPTIMIZER'] + '_' + str(params['LR'])\n",
    "\n",
    "params['MODEL_NAME'] = set_model_name(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3a9XanxFpp7"
   },
   "source": [
    "Now, we create a `TranslationModel` instance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2RYqrU6VFr8U",
    "outputId": "e332c74d-d740-43d9-d1d0-43c94b5d655f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:44] <<< Building AttentionRNNEncoderDecoder Translation_Model >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:650: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:44] From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:650: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4786: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:44] From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4786: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:247: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:44] From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:247: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:250: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:44] From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:250: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3561: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:49] From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3561: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------\n",
      "\t\tTranslationModel instance\n",
      "-----------------------------------------------------------------------------------\n",
      "_model_type: AttentionRNNEncoderDecoder\n",
      "name: tutorial_model\n",
      "model_path: trained_models/tutorial_model/\n",
      "verbose: True\n",
      "\n",
      "Params:\n",
      "\tACCUMULATE_GRADIENTS: 1\n",
      "\tADDITIONAL_OUTPUT_MERGE_MODE: Add\n",
      "\tALIGN_FROM_RAW: True\n",
      "\tALPHA_FACTOR: 0.6\n",
      "\tAMSGRAD: False\n",
      "\tAPPLY_DETOKENIZATION: False\n",
      "\tATTENTION_DROPOUT_P: 0.2\n",
      "\tATTENTION_MODE: add\n",
      "\tATTENTION_SIZE: 512\n",
      "\tBATCH_NORMALIZATION_MODE: 1\n",
      "\tBATCH_SIZE: 72\n",
      "\tBEAM_SEARCH: True\n",
      "\tBEAM_SIZE: 1\n",
      "\tBETA_1: 0.9\n",
      "\tBETA_2: 0.999\n",
      "\tBIDIRECTIONAL_DEEP_ENCODER: True\n",
      "\tBIDIRECTIONAL_ENCODER: True\n",
      "\tBIDIRECTIONAL_MERGE_MODE: concat\n",
      "\tBPE_CODES_PATH: examples/EuTrans//training_codes.joint\n",
      "\tCLASSIFIER_ACTIVATION: softmax\n",
      "\tCLIP_C: 5.0\n",
      "\tCLIP_V: 0.0\n",
      "\tCOVERAGE_NORM_FACTOR: 0.2\n",
      "\tCOVERAGE_PENALTY: True\n",
      "\tDATASET_NAME: ASTDocstring\n",
      "\tDATASET_STORE_PATH: datasets/\n",
      "\tDATA_AUGMENTATION: False\n",
      "\tDATA_ROOT_PATH: \n",
      "\tDECODER_HIDDEN_SIZE: 512\n",
      "\tDECODER_RNN_TYPE: ConditionalLSTM\n",
      "\tDEEP_OUTPUT_LAYERS: [('linear', 512)]\n",
      "\tDETOKENIZATION_METHOD: detokenize_none\n",
      "\tDOUBLE_STOCHASTIC_ATTENTION_REG: 0.0\n",
      "\tDROPOUT_P: 0.2\n",
      "\tEARLY_STOP: True\n",
      "\tEMBEDDINGS_FREQ: 1\n",
      "\tENCODER_HIDDEN_SIZE: 512\n",
      "\tENCODER_RNN_TYPE: LSTM\n",
      "\tEPOCHS_FOR_SAVE: 5\n",
      "\tEPSILON: 1e-08\n",
      "\tEVAL_EACH: 1\n",
      "\tEVAL_EACH_EPOCHS: True\n",
      "\tEVAL_ON_SETS: ['train', 'val']\n",
      "\tEXTRA_NAME: \n",
      "\tFF_SIZE: 128\n",
      "\tFILL: end\n",
      "\tFORCE_RELOAD_VOCABULARY: False\n",
      "\tGLOSSARY: None\n",
      "\tGRU_RESET_AFTER: True\n",
      "\tHEURISTIC: 0\n",
      "\tHOMOGENEOUS_BATCHES: False\n",
      "\tINIT_ATT: glorot_uniform\n",
      "\tINIT_FUNCTION: glorot_uniform\n",
      "\tINIT_LAYERS: ['tanh']\n",
      "\tINNER_INIT: orthogonal\n",
      "\tINPUTS_IDS_DATASET: ['source_text', 'state_below']\n",
      "\tINPUTS_IDS_MODEL: ['source_text', 'state_below']\n",
      "\tINPUTS_TYPES_DATASET: ['text-features', 'text-features']\n",
      "\tINPUT_VOCABULARY_SIZE: 141\n",
      "\tJOINT_BATCHES: 4\n",
      "\tKERAS_METRICS: ['perplexity']\n",
      "\tLABEL_SMOOTHING: 0.1\n",
      "\tLENGTH_NORM_FACTOR: 0.2\n",
      "\tLENGTH_PENALTY: True\n",
      "\tLOG_DIR: tensorboard_logs\n",
      "\tLOSS: categorical_crossentropy\n",
      "\tLR: 0.0002\n",
      "\tLR_DECAY: None\n",
      "\tLR_GAMMA: 0.8\n",
      "\tLR_HALF_LIFE: 100\n",
      "\tLR_REDUCER_EXP_BASE: -0.5\n",
      "\tLR_REDUCER_TYPE: exponential\n",
      "\tLR_REDUCE_EACH_EPOCHS: False\n",
      "\tLR_START_REDUCTION_ON_EPOCH: 0\n",
      "\tMAPPING: examples/EuTrans//mapping.es_en.pkl\n",
      "\tMAXLEN_GIVEN_X: False\n",
      "\tMAXLEN_GIVEN_X_FACTOR: 2\n",
      "\tMAX_EPOCH: 500\n",
      "\tMAX_INPUT_TEXT_LEN: 300\n",
      "\tMAX_OUTPUT_TEXT_LEN: 10\n",
      "\tMAX_OUTPUT_TEXT_LEN_TEST: 150\n",
      "\tMAX_PLOT_Y: 100.0\n",
      "\tMETRICS: ['sacrebleu', 'perplexity']\n",
      "\tMINLEN_GIVEN_X: False\n",
      "\tMINLEN_GIVEN_X_FACTOR: 3\n",
      "\tMIN_DELTA: 0.0\n",
      "\tMIN_LR: 1e-09\n",
      "\tMIN_OCCURRENCES_INPUT_VOCAB: 0\n",
      "\tMIN_OCCURRENCES_OUTPUT_VOCAB: 0\n",
      "\tMODE: training\n",
      "\tMODEL_NAME: ASTDocstring_asten_AttentionRNNEncoderDecoder_src_emb_512_bidir_True_enc_LSTM_512_dec_ConditionalLSTM_512_deepout_linear_trg_emb_512_Adam_0.0002\n",
      "\tMODEL_SIZE: 512\n",
      "\tMODEL_TYPE: AttentionRNNEncoderDecoder\n",
      "\tMOMENTUM: 0.0\n",
      "\tMULTIHEAD_ATTENTION_ACTIVATION: linear\n",
      "\tNESTEROV_MOMENTUM: False\n",
      "\tNOISE_AMOUNT: 0.01\n",
      "\tNORMALIZE_SAMPLING: False\n",
      "\tN_GPUS: 0\n",
      "\tN_HEADS: 8\n",
      "\tN_LAYERS_DECODER: 2\n",
      "\tN_LAYERS_ENCODER: 2\n",
      "\tN_SAMPLES: 5\n",
      "\tOPTIMIZED_SEARCH: True\n",
      "\tOPTIMIZER: Adam\n",
      "\tOUTPUTS_IDS_DATASET: ['target_text']\n",
      "\tOUTPUTS_IDS_MODEL: ['target_text']\n",
      "\tOUTPUTS_TYPES_DATASET: ['text-features']\n",
      "\tOUTPUT_VOCABULARY_SIZE: 24657\n",
      "\tPAD_ON_BATCH: True\n",
      "\tPARALLEL_LOADERS: 1\n",
      "\tPATIENCE: 3\n",
      "\tPLOT_EVALUATION: True\n",
      "\tPOS_UNK: True\n",
      "\tREBUILD_DATASET: True\n",
      "\tRECURRENT_DROPOUT_P: 0.0\n",
      "\tRECURRENT_INPUT_DROPOUT_P: 0.0\n",
      "\tRECURRENT_WEIGHT_DECAY: 0.0\n",
      "\tREGULARIZATION_FN: L2\n",
      "\tRELOAD: 0\n",
      "\tRELOAD_EPOCH: True\n",
      "\tRHO: 0.9\n",
      "\tSAMPLE_EACH_UPDATES: 300\n",
      "\tSAMPLE_ON_SETS: ['train', 'val']\n",
      "\tSAMPLE_WEIGHTS: True\n",
      "\tSAMPLING: max_likelihood\n",
      "\tSAMPLING_SAVE_MODE: list\n",
      "\tSAVE_EACH_EVALUATION: True\n",
      "\tSCALE_SOURCE_WORD_EMBEDDINGS: False\n",
      "\tSCALE_TARGET_WORD_EMBEDDINGS: False\n",
      "\tSEARCH_PRUNING: False\n",
      "\tSKIP_VECTORS_HIDDEN_SIZE: 512\n",
      "\tSKIP_VECTORS_SHARED_ACTIVATION: tanh\n",
      "\tSOURCE_TEXT_EMBEDDING_SIZE: 512\n",
      "\tSRC_LAN: ast\n",
      "\tSRC_PRETRAINED_VECTORS: None\n",
      "\tSRC_PRETRAINED_VECTORS_TRAINABLE: True\n",
      "\tSTART_EVAL_ON_EPOCH: 1\n",
      "\tSTART_SAMPLING_ON_EPOCH: 1\n",
      "\tSTOP_METRIC: Bleu_4\n",
      "\tSTORE_PATH: trained_models/EuTrans_esen_AttentionRNNEncoderDecoder_src_emb_32_bidir_True_enc_LSTM_32_dec_ConditionalLSTM_32_deepout_linear_trg_emb_32_Adam_0.001/\n",
      "\tTARGET_TEXT_EMBEDDING_SIZE: 512\n",
      "\tTASK_NAME: ASTDocstring\n",
      "\tTEMPERATURE: 1\n",
      "\tTENSORBOARD: True\n",
      "\tTEXT_FILES: {'train': 'training.', 'val': 'dev.', 'test': 'test.'}\n",
      "\tTIE_EMBEDDINGS: False\n",
      "\tTOKENIZATION_METHOD: tokenize_none\n",
      "\tTOKENIZE_HYPOTHESES: True\n",
      "\tTOKENIZE_REFERENCES: True\n",
      "\tTRAINABLE_DECODER: True\n",
      "\tTRAINABLE_ENCODER: True\n",
      "\tTRAIN_ON_TRAINVAL: False\n",
      "\tTRG_LAN: en\n",
      "\tTRG_PRETRAINED_VECTORS: None\n",
      "\tTRG_PRETRAINED_VECTORS_TRAINABLE: True\n",
      "\tUSE_BATCH_NORMALIZATION: False\n",
      "\tUSE_CUDNN: False\n",
      "\tUSE_L1: False\n",
      "\tUSE_L2: False\n",
      "\tUSE_NOISE: False\n",
      "\tUSE_PRELU: False\n",
      "\tUSE_TF_OPTIMIZER: True\n",
      "\tVERBOSE: 1\n",
      "\tWARMUP_EXP: -1.5\n",
      "\tWEIGHT_DECAY: 0.0001\n",
      "\tWRITE_VALID_SAMPLES: True\n",
      "\tnum_examples: 25000\n",
      "\ttokenize_x: tokenize_none\n",
      "\ttokenize_y: tokenize_none\n",
      "\tx_max_text_len: 300\n",
      "\tx_max_words: 200\n",
      "\ty_max_text_len: 10\n",
      "\ty_max_words: 30000\n",
      "\ty_min_occ: 0\n",
      "-----------------------------------------------------------------------------------\n",
      "Model: \"tutorial_model_training\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "source_text (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "source_word_embedding (Embeddin (None, None, 512)    72192       source_text[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "src_embedding_dropout (Dropout) (None, None, 512)    0           source_word_embedding[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "remove_mask_1 (RemoveMask)      (None, None, 512)    0           src_embedding_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_encoder_LSTM (Bid (None, None, 1024)   4198400     remove_mask_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "annotations_dropout (Dropout)   (None, None, 1024)   0           bidirectional_encoder_LSTM[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_encoder_1 (Bidire (None, None, 1024)   6295552     annotations_dropout[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "annotations_1_dropout (Dropout) (None, None, 1024)   0           bidirectional_encoder_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, 1024)   0           annotations_dropout[0][0]        \n",
      "                                                                 annotations_1_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "source_text_mask (GetMask)      (None, None, 512)    0           src_embedding_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "annotations (ApplyMask)         (None, None, 1024)   0           add_1[0][0]                      \n",
      "                                                                 source_text_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "state_below (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctx_mean (MaskedMean)           (None, 1024)         0           annotations[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "target_word_embedding (Embeddin (None, None, 512)    12624384    state_below[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "initial_state (Dense)           (None, 512)          524800      ctx_mean[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "initial_memory (Dense)          (None, 512)          524800      ctx_mean[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "state_below_dropout (Dropout)   (None, None, 512)    0           target_word_embedding[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "initial_state_dropout (Dropout) (None, 512)          0           initial_state[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "initial_memory_dropout (Dropout (None, 512)          0           initial_memory[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_AttConditionalLSTMCond  [(None, None, 512),  6034433     state_below_dropout[0][0]        \n",
      "                                                                 annotations[0][0]                \n",
      "                                                                 initial_state_dropout[0][0]      \n",
      "                                                                 initial_memory_dropout[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "proj_h0_dropout (Dropout)       (None, None, 512)    0           decoder_AttConditionalLSTMCond[0]\n",
      "__________________________________________________________________________________________________\n",
      "permute_general_1 (PermuteGener multiple             0           decoder_AttConditionalLSTMCond[0]\n",
      "                                                                 logit_ctx[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_LSTMCond1 (LSTMCond)    [(None, None, 512),  4196352     proj_h0_dropout[0][0]            \n",
      "                                                                 permute_general_1[0][0]          \n",
      "                                                                 initial_state_dropout[0][0]      \n",
      "                                                                 initial_memory_dropout[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "proj_h1_dropout (Dropout)       (None, None, 512)    0           decoder_LSTMCond1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, 512)    0           proj_h0_dropout[0][0]            \n",
      "                                                                 proj_h1_dropout[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "logit_ctx (TimeDistributed)     (None, None, 512)    524800      decoder_AttConditionalLSTMCond[0]\n",
      "__________________________________________________________________________________________________\n",
      "logit_lstm (TimeDistributed)    (None, None, 512)    262656      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "logit_emb (TimeDistributed)     (None, None, 512)    262656      state_below_dropout[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "out_layer_mlp_dropout (Dropout) (None, None, 512)    0           logit_lstm[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "out_layer_ctx_dropout (Dropout) (None, None, 512)    0           permute_general_1[1][0]          \n",
      "__________________________________________________________________________________________________\n",
      "out_layer_emb_dropout (Dropout) (None, None, 512)    0           logit_emb[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "additional_input (Add)          (None, None, 512)    0           out_layer_mlp_dropout[0][0]      \n",
      "                                                                 out_layer_ctx_dropout[0][0]      \n",
      "                                                                 out_layer_emb_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 512)    0           additional_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "linear_0 (TimeDistributed)      (None, None, 512)    262656      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "out_layer_linear_0_dropout (Dro (None, None, 512)    0           linear_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "target_text (TimeDistributed)   (None, None, 24657)  12649041    out_layer_linear_0_dropout[0][0] \n",
      "==================================================================================================\n",
      "Total params: 48,432,722\n",
      "Trainable params: 48,432,722\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /mnt/c/Users/sagun/Downloads/ComGen/nmt-keras/nmt_keras/model_zoo.py:213: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:51] From /mnt/c/Users/sagun/Downloads/ComGen/nmt-keras/nmt_keras/model_zoo.py:213: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "[16/04/2021 15:25:51] Preparing optimizer and compiling. Optimizer configuration: \n",
      "\t LR: 0.0002\n",
      "\t LOSS: categorical_crossentropy\n",
      "\t BETA_1: 0.9\n",
      "\t BETA_2: 0.999\n",
      "\t EPSILON: 1e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1192: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:51] From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1192: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nmt_model = TranslationModel(params,\n",
    "                             model_type=params['MODEL_TYPE'], \n",
    "                             model_name='tutorial_model',\n",
    "                             vocabularies=dataset.vocabulary,\n",
    "                             store_path='trained_models/tutorial_model/',\n",
    "                             verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKQqWOneGD_3"
   },
   "source": [
    "Next, we must define the inputs and outputs mapping from our Dataset instance to our model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "VqEqWxYHGIM5"
   },
   "outputs": [],
   "source": [
    "inputMapping = dict()\n",
    "for i, id_in in enumerate(params['INPUTS_IDS_DATASET']):\n",
    "    pos_source = dataset.ids_inputs.index(id_in)\n",
    "    id_dest = nmt_model.ids_inputs[i]\n",
    "    inputMapping[id_dest] = pos_source\n",
    "\n",
    "nmt_model.setInputsMapping(inputMapping)\n",
    "\n",
    "outputMapping = dict()\n",
    "for i, id_out in enumerate(params['OUTPUTS_IDS_DATASET']):\n",
    "    pos_target = dataset.ids_outputs.index(id_out)\n",
    "    id_dest = nmt_model.ids_outputs[i]\n",
    "    outputMapping[id_dest] = pos_target\n",
    "\n",
    "nmt_model.setOutputsMapping(outputMapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKPW2hv8GKMj"
   },
   "source": [
    "We can add some callbacks for controlling the training (e.g. Sampling each N updates, early stop, learning rate annealing...). For instance, let's build a sampling callback. After each epoch, it will compute the BLEU scores on the development set using the sacreBLEU package. We need to pass some configuration variables to the callback (in the extra_vars dictionary):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "7MtMvSoAGNHb"
   },
   "outputs": [],
   "source": [
    "search_params = {\n",
    "    'language': 'en',\n",
    "    'tokenize_f': eval('dataset.' + tokenize_x),\n",
    "    'beam_size': beam_size,\n",
    "    'optimized_search': True,\n",
    "    'model_inputs': params['INPUTS_IDS_MODEL'],\n",
    "    'model_outputs': params['OUTPUTS_IDS_MODEL'],\n",
    "    'dataset_inputs':  params['INPUTS_IDS_DATASET'],\n",
    "    'dataset_outputs':  params['OUTPUTS_IDS_DATASET'],\n",
    "    'n_parallel_loaders': n_parallel_loaders,\n",
    "    'maxlen': y_max_text_len,\n",
    "    'normalize_probs': True,\n",
    "    'pos_unk': True and not is_transformer,  # Pos_unk is unimplemented for transformer models\n",
    "    'heuristic': 0,\n",
    "    'state_below_maxlen': -1,\n",
    "    'attend_on_output': is_transformer,\n",
    "    'val': {'references': dataset.extra_variables['val']['target_text']}\n",
    "  }\n",
    "\n",
    "vocab = dataset.vocabulary['target_text']['idx2words']\n",
    "callbacks = []\n",
    "input_text_id = params['INPUTS_IDS_DATASET'][0]\n",
    "\n",
    "callbacks.append(PrintPerformanceMetricOnEpochEndOrEachNUpdates(nmt_model,\n",
    "                                                                dataset,\n",
    "                                                                gt_id='target_text',\n",
    "                                                                metric_name=['sacrebleu'],\n",
    "                                                                set_name=['val'],\n",
    "                                                                batch_size=batch_size,\n",
    "                                                                each_n_epochs=1,\n",
    "                                                                extra_vars=search_params,\n",
    "                                                                reload_epoch=0,\n",
    "                                                                is_text=True,\n",
    "                                                                input_text_id=input_text_id,\n",
    "                                                                index2word_y=vocab,\n",
    "                                                                sampling_type='max_likelihood',\n",
    "                                                                beam_search=True,\n",
    "                                                                save_path=nmt_model.model_path,\n",
    "                                                                start_eval_on_epoch=0,\n",
    "                                                                write_samples=True,\n",
    "                                                                write_type='list',\n",
    "                                                                verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vo-kOSLlGQux"
   },
   "source": [
    "Now we are ready to train. Let's set up some training parameters...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "_-oborMLGUMP"
   },
   "outputs": [],
   "source": [
    "n_epochs = 35\n",
    "training_params = {'n_epochs': n_epochs,\n",
    "                   'batch_size': batch_size,\n",
    "                   'maxlen': y_max_text_len,\n",
    "                   'epochs_for_save': 1,\n",
    "                   'verbose': 1,\n",
    "                   'eval_on_sets': [], \n",
    "                   'n_parallel_loaders': n_parallel_loaders,\n",
    "                   'extra_callbacks': callbacks,\n",
    "                   'reload_epoch': 0,\n",
    "                   'epoch_offset': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7m3oR5RGVDp"
   },
   "source": [
    "And train!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PcyAKL4cGai4",
    "outputId": "a462bb32-6592-425a-a671-dbd36a3904a3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:51] <<< Training model >>>\n",
      "[16/04/2021 15:25:51] Training parameters: { \n",
      "\tbatch_size: 72\n",
      "\tclass_weights: None\n",
      "\tda_enhance_list: []\n",
      "\tda_patch_type: resize_and_rndcrop\n",
      "\tdata_augmentation: False\n",
      "\teach_n_epochs: 1\n",
      "\tepoch_offset: 0\n",
      "\tepochs_for_save: 1\n",
      "\teval_on_epochs: True\n",
      "\teval_on_sets: []\n",
      "\textra_callbacks: [<keras_wrapper.extra.callbacks.EvalPerformance object at 0x7fbd167cec50>]\n",
      "\thomogeneous_batches: False\n",
      "\tinitial_lr: 1.0\n",
      "\tjoint_batches: 4\n",
      "\tlr_decay: None\n",
      "\tlr_gamma: 0.1\n",
      "\tlr_half_life: 50000\n",
      "\tlr_reducer_exp_base: 0.5\n",
      "\tlr_reducer_type: linear\n",
      "\tlr_warmup_exp: -1.5\n",
      "\tmaxlen: 10\n",
      "\tmean_substraction: False\n",
      "\tmetric_check: None\n",
      "\tmin_delta: 0.0\n",
      "\tmin_lr: 1e-09\n",
      "\tn_epochs: 35\n",
      "\tn_gpus: 1\n",
      "\tn_parallel_loaders: 3\n",
      "\tnormalization_type: None\n",
      "\tnormalize: False\n",
      "\tnum_iterations_val: None\n",
      "\tpatience: 0\n",
      "\tpatience_check_split: val\n",
      "\treduce_each_epochs: True\n",
      "\treload_epoch: 0\n",
      "\tshuffle: True\n",
      "\tstart_eval_on_epoch: 0\n",
      "\tstart_reduction_on_epoch: 0\n",
      "\ttensorboard: False\n",
      "\ttensorboard_params: {'log_dir': 'tensorboard_logs', 'histogram_freq': 0, 'batch_size': 50, 'write_graph': True, 'write_grads': False, 'write_images': False, 'embeddings_freq': 0, 'embeddings_layer_names': None, 'embeddings_metadata': None, 'update_freq': 'epoch'}\n",
      "\tverbose: 1\n",
      "\two_da_patch_type: whole\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3315: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:56] From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3315: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:292: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:57] From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:292: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:299: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:57] From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:299: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:312: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:57] From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:312: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:321: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:57] From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:321: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "[16/04/2021 15:25:57] Starting dataLoad_process_0...\n",
      "[16/04/2021 15:25:57] Starting dataLoad_process_1...\n",
      "[16/04/2021 15:25:57] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:328: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 15:25:59] From /home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:328: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "282/282 [==============================] - 7376s 26s/step - loss: 6.2506 - perplexity: 30161.0742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 17:29:00] <<< Saving model to trained_models/tutorial_model/epoch_1 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras/engine/saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n",
      "[16/04/2021 17:29:07] <<< Model saved >>>\n",
      "\n",
      "[16/04/2021 17:29:07] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 17:29:07] Starting dataLoad_process_0...\n",
      "[16/04/2021 17:29:07] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 17:29:07] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 24451.398356 \t Average cost: 10.867288\n",
      "The sampling took: 1040.291370 secs (Speed: 0.462352 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 17:46:28] Prediction output 0: target_text (text)\n",
      "[16/04/2021 17:46:28] Decoding beam search prediction ...\n",
      "[16/04/2021 17:46:28] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 17:46:28] Evaluating on metric sacrebleu\n",
      "[16/04/2021 17:46:29] Computing SacreBleu scores on the val split...\n",
      "[16/04/2021 17:46:29] Bleu_4: 0.0006219908743789073\n",
      "[16/04/2021 17:46:29] Done evaluating on metric sacrebleu\n",
      "[16/04/2021 17:46:29] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_1.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/35\n",
      "282/282 [==============================] - 7240s 26s/step - loss: 5.6820 - perplexity: 17523.0977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 19:47:09] <<< Saving model to trained_models/tutorial_model/epoch_2 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 19:47:13] <<< Model saved >>>\n",
      "\n",
      "[16/04/2021 19:47:13] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 19:47:13] Starting dataLoad_process_0...\n",
      "[16/04/2021 19:47:13] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 19:47:13] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 55626.033251 \t Average cost: 24.722681\n",
      "The sampling took: 1272.530850 secs (Speed: 0.565569 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "[16/04/2021 20:08:26] Prediction output 0: target_text (text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 20:08:26] Decoding beam search prediction ...\n",
      "[16/04/2021 20:08:26] Using heuristic 0\n",
      "[16/04/2021 20:08:26] Evaluating on metric sacrebleu\n",
      "[16/04/2021 20:08:27] Computing SacreBleu scores on the val split...\n",
      "[16/04/2021 20:08:27] Bleu_4: 0.008743300035529103\n",
      "[16/04/2021 20:08:27] Done evaluating on metric sacrebleu\n",
      "[16/04/2021 20:08:27] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_2.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/35\n",
      "282/282 [==============================] - 7262s 26s/step - loss: 5.4825 - perplexity: 15020.8623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 22:09:29] <<< Saving model to trained_models/tutorial_model/epoch_3 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 22:09:33] <<< Model saved >>>\n",
      "\n",
      "[16/04/2021 22:09:33] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 22:09:34] Starting dataLoad_process_0...\n",
      "[16/04/2021 22:09:34] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 22:09:34] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 34829.093650 \t Average cost: 15.479597\n",
      "The sampling took: 1129.792567 secs (Speed: 0.502130 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 22:28:23] Prediction output 0: target_text (text)\n",
      "[16/04/2021 22:28:23] Decoding beam search prediction ...\n",
      "[16/04/2021 22:28:23] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/04/2021 22:28:24] Evaluating on metric sacrebleu\n",
      "[16/04/2021 22:28:25] Computing SacreBleu scores on the val split...\n",
      "[16/04/2021 22:28:25] Bleu_4: 0.026037360801057792\n",
      "[16/04/2021 22:28:25] Done evaluating on metric sacrebleu\n",
      "[16/04/2021 22:28:25] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_3.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/35\n",
      "282/282 [==============================] - 7278s 26s/step - loss: 5.3043 - perplexity: 11511.4385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 00:29:43] <<< Saving model to trained_models/tutorial_model/epoch_4 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 00:29:47] <<< Model saved >>>\n",
      "\n",
      "[17/04/2021 00:29:47] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 00:29:47] Starting dataLoad_process_0...\n",
      "[17/04/2021 00:29:47] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 00:29:47] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 42565.416300 \t Average cost: 18.917963\n",
      "The sampling took: 1209.775458 secs (Speed: 0.537678 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 00:49:56] Prediction output 0: target_text (text)\n",
      "[17/04/2021 00:49:56] Decoding beam search prediction ...\n",
      "[17/04/2021 00:49:56] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 00:49:57] Evaluating on metric sacrebleu\n",
      "[17/04/2021 00:49:58] Computing SacreBleu scores on the val split...\n",
      "[17/04/2021 00:49:58] Bleu_4: 0.0690840446559402\n",
      "[17/04/2021 00:49:58] Done evaluating on metric sacrebleu\n",
      "[17/04/2021 00:49:58] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_4.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/35\n",
      "282/282 [==============================] - 7293s 26s/step - loss: 5.2001 - perplexity: 8824.6943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 02:51:31] <<< Saving model to trained_models/tutorial_model/epoch_5 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 02:51:36] <<< Model saved >>>\n",
      "\n",
      "[17/04/2021 02:51:36] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 02:51:36] Starting dataLoad_process_0...\n",
      "[17/04/2021 02:51:36] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 02:51:36] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 43435.040771 \t Average cost: 19.304463\n",
      "The sampling took: 1274.371601 secs (Speed: 0.566387 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 03:12:50] Prediction output 0: target_text (text)\n",
      "[17/04/2021 03:12:50] Decoding beam search prediction ...\n",
      "[17/04/2021 03:12:50] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 03:12:50] Evaluating on metric sacrebleu\n",
      "[17/04/2021 03:12:51] Computing SacreBleu scores on the val split...\n",
      "[17/04/2021 03:12:51] Bleu_4: 0.09738125191831967\n",
      "[17/04/2021 03:12:51] Done evaluating on metric sacrebleu\n",
      "[17/04/2021 03:12:52] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_5.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/35\n",
      "282/282 [==============================] - 7190s 25s/step - loss: 5.1151 - perplexity: 7664.8096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 05:12:42] <<< Saving model to trained_models/tutorial_model/epoch_6 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 05:12:45] <<< Model saved >>>\n",
      "\n",
      "[17/04/2021 05:12:45] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 05:12:46] Starting dataLoad_process_0...\n",
      "[17/04/2021 05:12:46] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 05:12:46] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 44907.385447 \t Average cost: 19.958838\n",
      "The sampling took: 1229.836854 secs (Speed: 0.546594 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 05:33:15] Prediction output 0: target_text (text)\n",
      "[17/04/2021 05:33:15] Decoding beam search prediction ...\n",
      "[17/04/2021 05:33:15] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 05:33:16] Evaluating on metric sacrebleu\n",
      "[17/04/2021 05:33:17] Computing SacreBleu scores on the val split...\n",
      "[17/04/2021 05:33:17] Bleu_4: 0.060761989062814416\n",
      "[17/04/2021 05:33:17] Done evaluating on metric sacrebleu\n",
      "[17/04/2021 05:33:17] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_6.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/35\n",
      "282/282 [==============================] - 7123s 25s/step - loss: 5.0344 - perplexity: 6871.4404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 07:32:00] <<< Saving model to trained_models/tutorial_model/epoch_7 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 07:32:04] <<< Model saved >>>\n",
      "\n",
      "[17/04/2021 07:32:04] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 07:32:05] Starting dataLoad_process_0...\n",
      "[17/04/2021 07:32:05] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 07:32:05] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 45523.561676 \t Average cost: 20.232694\n",
      "The sampling took: 1202.506546 secs (Speed: 0.534447 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 07:52:07] Prediction output 0: target_text (text)\n",
      "[17/04/2021 07:52:07] Decoding beam search prediction ...\n",
      "[17/04/2021 07:52:07] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 07:52:07] Evaluating on metric sacrebleu\n",
      "[17/04/2021 07:52:08] Computing SacreBleu scores on the val split...\n",
      "[17/04/2021 07:52:08] Bleu_4: 0.04079821831695527\n",
      "[17/04/2021 07:52:08] Done evaluating on metric sacrebleu\n",
      "[17/04/2021 07:52:08] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_7.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/35\n",
      "282/282 [==============================] - 7032s 25s/step - loss: 4.9439 - perplexity: 6256.2598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 09:49:21] <<< Saving model to trained_models/tutorial_model/epoch_8 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 09:49:25] <<< Model saved >>>\n",
      "\n",
      "[17/04/2021 09:49:25] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 09:49:26] Starting dataLoad_process_0...\n",
      "[17/04/2021 09:49:26] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 09:49:26] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 43848.356569 \t Average cost: 19.488158\n",
      "The sampling took: 1206.325256 secs (Speed: 0.536145 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 10:09:32] Prediction output 0: target_text (text)\n",
      "[17/04/2021 10:09:32] Decoding beam search prediction ...\n",
      "[17/04/2021 10:09:32] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 10:09:32] Evaluating on metric sacrebleu\n",
      "[17/04/2021 10:09:33] Computing SacreBleu scores on the val split...\n",
      "[17/04/2021 10:09:33] Bleu_4: 0.05972202902975131\n",
      "[17/04/2021 10:09:33] Done evaluating on metric sacrebleu\n",
      "[17/04/2021 10:09:34] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_8.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/35\n",
      "282/282 [==============================] - 7204s 26s/step - loss: 4.8659 - perplexity: 6077.6611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 12:09:37] <<< Saving model to trained_models/tutorial_model/epoch_9 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 12:09:41] <<< Model saved >>>\n",
      "\n",
      "[17/04/2021 12:09:41] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 12:09:42] Starting dataLoad_process_0...\n",
      "[17/04/2021 12:09:42] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 12:09:42] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 41775.026077 \t Average cost: 18.566678\n",
      "The sampling took: 1210.803188 secs (Speed: 0.538135 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-38:\n",
      "Process Process-40:\n",
      "[17/04/2021 12:29:52] Prediction output 0: target_text (text)\n",
      "[17/04/2021 12:29:52] Decoding beam search prediction ...\n",
      "[17/04/2021 12:29:52] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 12:29:53] Evaluating on metric sacrebleu\n",
      "[17/04/2021 12:29:54] Computing SacreBleu scores on the val split...\n",
      "[17/04/2021 12:29:54] Bleu_4: 0.04818866946356772\n",
      "[17/04/2021 12:29:54] Done evaluating on metric sacrebleu\n",
      "[17/04/2021 12:29:54] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_9.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/35\n",
      "282/282 [==============================] - 7090s 25s/step - loss: 4.7872 - perplexity: 5889.7642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 14:28:03] <<< Saving model to trained_models/tutorial_model/epoch_10 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 14:28:08] <<< Model saved >>>\n",
      "\n",
      "[17/04/2021 14:28:08] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 14:28:08] Starting dataLoad_process_0...\n",
      "[17/04/2021 14:28:08] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 14:28:08] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 37889.195555 \t Average cost: 16.839642\n",
      "The sampling took: 1178.581727 secs (Speed: 0.523814 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-44:\n",
      "Process Process-42:\n",
      "[17/04/2021 14:47:47] Prediction output 0: target_text (text)\n",
      "[17/04/2021 14:47:47] Decoding beam search prediction ...\n",
      "[17/04/2021 14:47:47] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 14:47:47] Evaluating on metric sacrebleu\n",
      "[17/04/2021 14:47:48] Computing SacreBleu scores on the val split...\n",
      "[17/04/2021 14:47:48] Bleu_4: 0.05305058645166982\n",
      "[17/04/2021 14:47:48] Done evaluating on metric sacrebleu\n",
      "[17/04/2021 14:47:48] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_10.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/35\n",
      "282/282 [==============================] - 7085s 25s/step - loss: 4.7202 - perplexity: 6012.3594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 16:45:53] <<< Saving model to trained_models/tutorial_model/epoch_11 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 16:45:57] <<< Model saved >>>\n",
      "\n",
      "[17/04/2021 16:45:57] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 16:45:58] Starting dataLoad_process_0...\n",
      "[17/04/2021 16:45:58] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 16:45:58] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 39129.857493 \t Average cost: 17.391048\n",
      "The sampling took: 1212.492057 secs (Speed: 0.538885 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-47:\n",
      "[17/04/2021 17:06:10] Prediction output 0: target_text (text)\n",
      "[17/04/2021 17:06:10] Decoding beam search prediction ...\n",
      "[17/04/2021 17:06:10] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 17:06:10] Evaluating on metric sacrebleu\n",
      "[17/04/2021 17:06:12] Computing SacreBleu scores on the val split...\n",
      "[17/04/2021 17:06:12] Bleu_4: 0.049887416212350946\n",
      "[17/04/2021 17:06:12] Done evaluating on metric sacrebleu\n",
      "[17/04/2021 17:06:12] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_11.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/35\n",
      "282/282 [==============================] - 7186s 25s/step - loss: 4.6551 - perplexity: 5912.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 19:05:57] <<< Saving model to trained_models/tutorial_model/epoch_12 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 19:06:01] <<< Model saved >>>\n",
      "\n",
      "[17/04/2021 19:06:01] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 19:06:02] Starting dataLoad_process_0...\n",
      "[17/04/2021 19:06:02] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 19:06:02] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 39076.260707 \t Average cost: 17.367227\n",
      "The sampling took: 1201.420053 secs (Speed: 0.533964 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-50:\n",
      "Process Process-51:\n",
      "[17/04/2021 19:26:03] Prediction output 0: target_text (text)\n",
      "[17/04/2021 19:26:03] Decoding beam search prediction ...\n",
      "[17/04/2021 19:26:03] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 19:26:04] Evaluating on metric sacrebleu\n",
      "[17/04/2021 19:26:05] Computing SacreBleu scores on the val split...\n",
      "[17/04/2021 19:26:05] Bleu_4: 0.08473453083917994\n",
      "[17/04/2021 19:26:05] Done evaluating on metric sacrebleu\n",
      "[17/04/2021 19:26:05] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_12.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/35\n",
      "282/282 [==============================] - 7274s 26s/step - loss: 4.5919 - perplexity: 6421.1992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 21:27:19] <<< Saving model to trained_models/tutorial_model/epoch_13 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 21:27:23] <<< Model saved >>>\n",
      "\n",
      "[17/04/2021 21:27:23] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 21:27:23] Starting dataLoad_process_0...\n",
      "[17/04/2021 21:27:24] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 21:27:24] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 39089.395638 \t Average cost: 17.373065\n",
      "The sampling took: 1220.886541 secs (Speed: 0.542616 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-56:\n",
      "Process Process-55:\n",
      "[17/04/2021 21:47:44] Prediction output 0: target_text (text)\n",
      "[17/04/2021 21:47:44] Decoding beam search prediction ...\n",
      "[17/04/2021 21:47:44] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 21:47:44] Evaluating on metric sacrebleu\n",
      "[17/04/2021 21:47:46] Computing SacreBleu scores on the val split...\n",
      "[17/04/2021 21:47:46] Bleu_4: 0.12013956109902832\n",
      "[17/04/2021 21:47:46] Done evaluating on metric sacrebleu\n",
      "[17/04/2021 21:47:46] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_13.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/35\n",
      "282/282 [==============================] - 7065s 25s/step - loss: 4.5313 - perplexity: 6494.3721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 23:45:31] <<< Saving model to trained_models/tutorial_model/epoch_14 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 23:45:36] <<< Model saved >>>\n",
      "\n",
      "[17/04/2021 23:45:36] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 23:45:36] Starting dataLoad_process_0...\n",
      "[17/04/2021 23:45:36] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/04/2021 23:45:36] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 40400.578093 \t Average cost: 17.955812\n",
      "The sampling took: 1216.432401 secs (Speed: 0.540637 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-60:\n",
      "Process Process-58:\n",
      "Process Process-59:\n",
      "[18/04/2021 00:05:53] Prediction output 0: target_text (text)\n",
      "[18/04/2021 00:05:53] Decoding beam search prediction ...\n",
      "[18/04/2021 00:05:53] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 00:05:53] Evaluating on metric sacrebleu\n",
      "[18/04/2021 00:05:54] Computing SacreBleu scores on the val split...\n",
      "[18/04/2021 00:05:54] Bleu_4: 0.11034425685726669\n",
      "[18/04/2021 00:05:54] Done evaluating on metric sacrebleu\n",
      "[18/04/2021 00:05:54] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_14.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/35\n",
      "282/282 [==============================] - 7060s 25s/step - loss: 4.4749 - perplexity: 6510.4463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 02:03:34] <<< Saving model to trained_models/tutorial_model/epoch_15 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 02:03:38] <<< Model saved >>>\n",
      "\n",
      "[18/04/2021 02:03:38] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 02:03:39] Starting dataLoad_process_0...\n",
      "[18/04/2021 02:03:39] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 02:03:39] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 37723.384489 \t Average cost: 16.765949\n",
      "The sampling took: 1215.840103 secs (Speed: 0.540373 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 02:23:55] Prediction output 0: target_text (text)\n",
      "[18/04/2021 02:23:55] Decoding beam search prediction ...\n",
      "[18/04/2021 02:23:55] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 02:23:55] Evaluating on metric sacrebleu\n",
      "[18/04/2021 02:23:56] Computing SacreBleu scores on the val split...\n",
      "[18/04/2021 02:23:56] Bleu_4: 0.0929416891308544\n",
      "[18/04/2021 02:23:56] Done evaluating on metric sacrebleu\n",
      "[18/04/2021 02:23:56] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_15.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/35\n",
      "282/282 [==============================] - 7162s 25s/step - loss: 4.4247 - perplexity: 6731.4453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 04:23:19] <<< Saving model to trained_models/tutorial_model/epoch_16 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 04:23:23] <<< Model saved >>>\n",
      "\n",
      "[18/04/2021 04:23:23] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 04:23:23] Starting dataLoad_process_0...\n",
      "[18/04/2021 04:23:23] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 04:23:24] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 36878.947755 \t Average cost: 16.390643\n",
      "The sampling took: 1216.606910 secs (Speed: 0.540714 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-66:\n",
      "Process Process-68:\n",
      "Process Process-67:\n",
      "[18/04/2021 04:43:40] Prediction output 0: target_text (text)\n",
      "[18/04/2021 04:43:40] Decoding beam search prediction ...\n",
      "[18/04/2021 04:43:40] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 04:43:40] Evaluating on metric sacrebleu\n",
      "[18/04/2021 04:43:41] Computing SacreBleu scores on the val split...\n",
      "[18/04/2021 04:43:41] Bleu_4: 0.06756932775837114\n",
      "[18/04/2021 04:43:41] Done evaluating on metric sacrebleu\n",
      "[18/04/2021 04:43:42] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_16.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/35\n",
      "282/282 [==============================] - 7122s 25s/step - loss: 4.3727 - perplexity: 6758.8027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 06:42:24] <<< Saving model to trained_models/tutorial_model/epoch_17 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 06:42:28] <<< Model saved >>>\n",
      "\n",
      "[18/04/2021 06:42:28] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 06:42:28] Starting dataLoad_process_0...\n",
      "[18/04/2021 06:42:28] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 06:42:28] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 35778.132020 \t Average cost: 15.901392\n",
      "The sampling took: 1220.692078 secs (Speed: 0.542530 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 07:02:49] Prediction output 0: target_text (text)\n",
      "[18/04/2021 07:02:49] Decoding beam search prediction ...\n",
      "[18/04/2021 07:02:49] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 07:02:49] Evaluating on metric sacrebleu\n",
      "[18/04/2021 07:02:50] Computing SacreBleu scores on the val split...\n",
      "[18/04/2021 07:02:50] Bleu_4: 0.06537464643392177\n",
      "[18/04/2021 07:02:51] Done evaluating on metric sacrebleu\n",
      "[18/04/2021 07:02:51] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_17.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/35\n",
      "282/282 [==============================] - 7085s 25s/step - loss: 4.3273 - perplexity: 6923.2871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 09:00:56] <<< Saving model to trained_models/tutorial_model/epoch_18 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 09:01:00] <<< Model saved >>>\n",
      "\n",
      "[18/04/2021 09:01:00] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 09:01:01] Starting dataLoad_process_0...\n",
      "[18/04/2021 09:01:01] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 09:01:01] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 34418.492872 \t Average cost: 15.297108\n",
      "The sampling took: 1222.951955 secs (Speed: 0.543534 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-75:\n",
      "Process Process-74:\n",
      "[18/04/2021 09:21:24] Prediction output 0: target_text (text)\n",
      "[18/04/2021 09:21:24] Decoding beam search prediction ...\n",
      "[18/04/2021 09:21:24] Using heuristic 0\n",
      "Process Process-76:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 09:21:24] Evaluating on metric sacrebleu\n",
      "[18/04/2021 09:21:25] Computing SacreBleu scores on the val split...\n",
      "[18/04/2021 09:21:25] Bleu_4: 0.0853195515763497\n",
      "[18/04/2021 09:21:25] Done evaluating on metric sacrebleu\n",
      "[18/04/2021 09:21:25] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_18.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/35\n",
      "282/282 [==============================] - 7016s 25s/step - loss: 4.2782 - perplexity: 7103.1738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 11:18:21] <<< Saving model to trained_models/tutorial_model/epoch_19 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 11:18:25] <<< Model saved >>>\n",
      "\n",
      "[18/04/2021 11:18:25] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 11:18:26] Starting dataLoad_process_0...\n",
      "[18/04/2021 11:18:26] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 11:18:26] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 33499.877444 \t Average cost: 14.888834\n",
      "The sampling took: 1222.739854 secs (Speed: 0.543440 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 11:38:49] Prediction output 0: target_text (text)\n",
      "[18/04/2021 11:38:49] Decoding beam search prediction ...\n",
      "[18/04/2021 11:38:49] Using heuristic 0\n",
      "[18/04/2021 11:38:49] Evaluating on metric sacrebleu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 11:38:50] Computing SacreBleu scores on the val split...\n",
      "[18/04/2021 11:38:50] Bleu_4: 0.09298484653931278\n",
      "[18/04/2021 11:38:50] Done evaluating on metric sacrebleu\n",
      "[18/04/2021 11:38:50] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_19.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/35\n",
      "282/282 [==============================] - 7105s 25s/step - loss: 4.2326 - perplexity: 7023.2974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 13:37:15] <<< Saving model to trained_models/tutorial_model/epoch_20 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 13:37:19] <<< Model saved >>>\n",
      "\n",
      "[18/04/2021 13:37:19] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 13:37:20] Starting dataLoad_process_0...\n",
      "[18/04/2021 13:37:20] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 13:37:20] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 32606.482926 \t Average cost: 14.491770\n",
      "The sampling took: 1199.209845 secs (Speed: 0.532982 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-83:\n",
      "Process Process-84:\n",
      "Process Process-82:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/abstractsushi/miniconda3/envs/CD/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/abstractsushi/miniconda3/envs/CD/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras_wrapper/dataset.py\", line 55, in dataLoad\n",
      "    data_queue = in_queue.get()\n",
      "  File \"/home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras_wrapper/utils.py\", line 75, in get\n",
      "    return self.queue.get()\n",
      "[18/04/2021 13:57:19] Prediction output 0: target_text (text)\n",
      "[18/04/2021 13:57:19] Decoding beam search prediction ...\n",
      "[18/04/2021 13:57:19] Using heuristic 0\n",
      "[18/04/2021 13:57:19] Evaluating on metric sacrebleu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 13:57:20] Computing SacreBleu scores on the val split...\n",
      "[18/04/2021 13:57:20] Bleu_4: 0.117705977349935\n",
      "[18/04/2021 13:57:20] Done evaluating on metric sacrebleu\n",
      "[18/04/2021 14:03:11] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_20.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/35\n",
      "282/282 [==============================] - 7120s 25s/step - loss: 4.1857 - perplexity: 7335.7905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 16:01:50] <<< Saving model to trained_models/tutorial_model/epoch_21 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 16:01:54] <<< Model saved >>>\n",
      "\n",
      "[18/04/2021 16:01:54] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 16:01:55] Starting dataLoad_process_0...\n",
      "[18/04/2021 16:01:55] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 16:01:55] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 31890.866471 \t Average cost: 14.173718\n",
      "The sampling took: 1194.426609 secs (Speed: 0.530856 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-86:\n",
      "Process Process-88:\n",
      "[18/04/2021 16:21:49] Prediction output 0: target_text (text)\n",
      "[18/04/2021 16:21:49] Decoding beam search prediction ...\n",
      "[18/04/2021 16:21:49] Using heuristic 0\n",
      "[18/04/2021 16:21:50] Evaluating on metric sacrebleu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 16:21:51] Computing SacreBleu scores on the val split...\n",
      "[18/04/2021 16:21:51] Bleu_4: 0.09318625555133535\n",
      "[18/04/2021 16:21:51] Done evaluating on metric sacrebleu\n",
      "[18/04/2021 16:21:51] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_21.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/35\n",
      "282/282 [==============================] - 7106s 25s/step - loss: 4.1357 - perplexity: 7087.9966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 18:20:17] <<< Saving model to trained_models/tutorial_model/epoch_22 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 18:20:21] <<< Model saved >>>\n",
      "\n",
      "[18/04/2021 18:20:21] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 18:20:22] Starting dataLoad_process_0...\n",
      "[18/04/2021 18:20:22] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 18:20:22] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 31826.136719 \t Average cost: 14.144950\n",
      "The sampling took: 1182.855563 secs (Speed: 0.525714 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 18:40:05] Prediction output 0: target_text (text)\n",
      "[18/04/2021 18:40:05] Decoding beam search prediction ...\n",
      "[18/04/2021 18:40:05] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 18:40:05] Evaluating on metric sacrebleu\n",
      "[18/04/2021 18:40:06] Computing SacreBleu scores on the val split...\n",
      "[18/04/2021 18:40:06] Bleu_4: 0.10068305276378431\n",
      "[18/04/2021 18:40:06] Done evaluating on metric sacrebleu\n",
      "[18/04/2021 18:40:07] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_22.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/35\n",
      "282/282 [==============================] - 7104s 25s/step - loss: 4.0940 - perplexity: 7048.2393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 20:38:30] <<< Saving model to trained_models/tutorial_model/epoch_23 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 20:38:34] <<< Model saved >>>\n",
      "\n",
      "[18/04/2021 20:38:34] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 20:38:35] Starting dataLoad_process_0...\n",
      "[18/04/2021 20:38:35] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 20:38:35] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 32947.663157 \t Average cost: 14.643406\n",
      "The sampling took: 1221.485818 secs (Speed: 0.542883 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-95:\n",
      "Process Process-94:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/abstractsushi/miniconda3/envs/CD/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "[18/04/2021 20:58:56] Prediction output 0: target_text (text)\n",
      "[18/04/2021 20:58:56] Decoding beam search prediction ...\n",
      "[18/04/2021 20:58:56] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 20:58:57] Evaluating on metric sacrebleu\n",
      "[18/04/2021 20:58:58] Computing SacreBleu scores on the val split...\n",
      "[18/04/2021 20:58:58] Bleu_4: 0.18830164009839012\n",
      "[18/04/2021 20:58:58] Done evaluating on metric sacrebleu\n",
      "[18/04/2021 20:58:58] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_23.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/35\n",
      "282/282 [==============================] - 7066s 25s/step - loss: 4.0315 - perplexity: 7050.3228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 22:56:44] <<< Saving model to trained_models/tutorial_model/epoch_24 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 22:56:49] <<< Model saved >>>\n",
      "\n",
      "[18/04/2021 22:56:49] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 22:56:50] Starting dataLoad_process_0...\n",
      "[18/04/2021 22:56:50] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 22:56:50] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 31869.066650 \t Average cost: 14.164030\n",
      "The sampling took: 1216.368701 secs (Speed: 0.540608 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 23:17:06] Prediction output 0: target_text (text)\n",
      "[18/04/2021 23:17:06] Decoding beam search prediction ...\n",
      "[18/04/2021 23:17:06] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/04/2021 23:17:06] Evaluating on metric sacrebleu\n",
      "[18/04/2021 23:17:07] Computing SacreBleu scores on the val split...\n",
      "[18/04/2021 23:17:07] Bleu_4: 0.1449425468879415\n",
      "[18/04/2021 23:17:07] Done evaluating on metric sacrebleu\n",
      "[18/04/2021 23:17:08] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_24.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/35\n",
      "282/282 [==============================] - 7281s 26s/step - loss: 3.9919 - perplexity: 7042.9360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 01:18:29] <<< Saving model to trained_models/tutorial_model/epoch_25 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 01:18:33] <<< Model saved >>>\n",
      "\n",
      "[19/04/2021 01:18:33] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 01:18:33] Starting dataLoad_process_0...\n",
      "[19/04/2021 01:18:33] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 01:18:34] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 30467.970997 \t Average cost: 13.541320\n",
      "The sampling took: 1212.267044 secs (Speed: 0.538785 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-104:\n",
      "Process Process-103:\n",
      "Process Process-102:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/abstractsushi/miniconda3/envs/CD/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/abstractsushi/miniconda3/envs/CD/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras_wrapper/dataset.py\", line 55, in dataLoad\n",
      "    data_queue = in_queue.get()\n",
      "Traceback (most recent call last):\n",
      "[19/04/2021 01:38:46] Prediction output 0: target_text (text)\n",
      "[19/04/2021 01:38:46] Decoding beam search prediction ...\n",
      "[19/04/2021 01:38:46] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 01:38:46] Evaluating on metric sacrebleu\n",
      "[19/04/2021 01:38:47] Computing SacreBleu scores on the val split...\n",
      "[19/04/2021 01:38:47] Bleu_4: 0.170334114772293\n",
      "[19/04/2021 01:38:47] Done evaluating on metric sacrebleu\n",
      "[19/04/2021 01:38:47] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_25.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/35\n",
      "282/282 [==============================] - 7114s 25s/step - loss: 3.9500 - perplexity: 7046.7944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 03:37:21] <<< Saving model to trained_models/tutorial_model/epoch_26 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 03:37:25] <<< Model saved >>>\n",
      "\n",
      "[19/04/2021 03:37:25] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 03:37:26] Starting dataLoad_process_0...\n",
      "[19/04/2021 03:37:26] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 03:37:26] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 30491.938382 \t Average cost: 13.551973\n",
      "The sampling took: 1209.134061 secs (Speed: 0.537393 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 03:57:34] Prediction output 0: target_text (text)\n",
      "[19/04/2021 03:57:34] Decoding beam search prediction ...\n",
      "[19/04/2021 03:57:34] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 03:57:34] Evaluating on metric sacrebleu\n",
      "[19/04/2021 03:57:36] Computing SacreBleu scores on the val split...\n",
      "[19/04/2021 03:57:36] Bleu_4: 0.16283153368755293\n",
      "[19/04/2021 03:57:36] Done evaluating on metric sacrebleu\n",
      "[19/04/2021 03:57:36] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_26.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/35\n",
      "282/282 [==============================] - 7223s 26s/step - loss: 3.9002 - perplexity: 7209.3960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 05:58:00] <<< Saving model to trained_models/tutorial_model/epoch_27 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 05:58:04] <<< Model saved >>>\n",
      "\n",
      "[19/04/2021 05:58:04] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 05:58:04] Starting dataLoad_process_0...\n",
      "[19/04/2021 05:58:04] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 05:58:04] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 29947.860256 \t Average cost: 13.310160\n",
      "The sampling took: 1213.184318 secs (Speed: 0.539193 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-110:\n",
      "Process Process-111:\n",
      "Process Process-112:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "[19/04/2021 06:18:17] Prediction output 0: target_text (text)\n",
      "[19/04/2021 06:18:17] Decoding beam search prediction ...\n",
      "[19/04/2021 06:18:17] Using heuristic 0\n",
      "[19/04/2021 06:18:18] Evaluating on metric sacrebleu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 06:18:19] Computing SacreBleu scores on the val split...\n",
      "[19/04/2021 06:18:19] Bleu_4: 0.19007684532889432\n",
      "[19/04/2021 06:18:19] Done evaluating on metric sacrebleu\n",
      "[19/04/2021 06:18:19] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_27.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/35\n",
      "282/282 [==============================] - 7078s 25s/step - loss: 3.8506 - perplexity: 6659.8320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 08:16:17] <<< Saving model to trained_models/tutorial_model/epoch_28 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 08:16:21] <<< Model saved >>>\n",
      "\n",
      "[19/04/2021 08:16:21] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 08:16:22] Starting dataLoad_process_0...\n",
      "[19/04/2021 08:16:22] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 08:16:22] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 29421.031721 \t Average cost: 13.076014\n",
      "The sampling took: 1192.026636 secs (Speed: 0.529790 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-115:\n",
      "Process Process-114:\n",
      "Process Process-116:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/abstractsushi/miniconda3/envs/CD/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/abstractsushi/miniconda3/envs/CD/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/abstractsushi/miniconda3/envs/CD/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/abstractsushi/miniconda3/envs/CD/lib/python3.7/site-packages/keras_wrapper/dataset.py\", line 55, in dataLoad\n",
      "    data_queue = in_queue.get()\n",
      "Traceback (most recent call last):\n",
      "[19/04/2021 08:36:13] Prediction output 0: target_text (text)\n",
      "[19/04/2021 08:36:13] Decoding beam search prediction ...\n",
      "[19/04/2021 08:36:13] Using heuristic 0\n",
      "[19/04/2021 08:36:14] Evaluating on metric sacrebleu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 08:36:15] Computing SacreBleu scores on the val split...\n",
      "[19/04/2021 08:36:15] Bleu_4: 0.16583366028477842\n",
      "[19/04/2021 08:36:15] Done evaluating on metric sacrebleu\n",
      "[19/04/2021 08:36:15] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_28.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/35\n",
      "282/282 [==============================] - 7043s 25s/step - loss: 3.8013 - perplexity: 6929.6426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 10:33:38] <<< Saving model to trained_models/tutorial_model/epoch_29 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 10:33:41] <<< Model saved >>>\n",
      "\n",
      "[19/04/2021 10:33:41] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 10:33:42] Starting dataLoad_process_0...\n",
      "[19/04/2021 10:33:42] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 10:33:42] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 28657.765712 \t Average cost: 12.736785\n",
      "The sampling took: 1215.856150 secs (Speed: 0.540381 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 10:53:57] Prediction output 0: target_text (text)\n",
      "[19/04/2021 10:53:57] Decoding beam search prediction ...\n",
      "[19/04/2021 10:53:57] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 10:53:57] Evaluating on metric sacrebleu\n",
      "[19/04/2021 10:53:59] Computing SacreBleu scores on the val split...\n",
      "[19/04/2021 10:53:59] Bleu_4: 0.1869248640295914\n",
      "[19/04/2021 10:53:59] Done evaluating on metric sacrebleu\n",
      "[19/04/2021 10:53:59] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_29.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/35\n",
      "282/282 [==============================] - 7147s 25s/step - loss: 3.7480 - perplexity: 6852.7856\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 12:53:07] <<< Saving model to trained_models/tutorial_model/epoch_30 ... >>>\n",
      "[19/04/2021 12:53:10] <<< Model saved >>>\n",
      "\n",
      "[19/04/2021 12:53:10] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 12:53:11] Starting dataLoad_process_0...\n",
      "[19/04/2021 12:53:12] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 12:53:12] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 28162.993889 \t Average cost: 12.516886\n",
      "The sampling took: 1216.699258 secs (Speed: 0.540755 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 13:13:28] Prediction output 0: target_text (text)\n",
      "[19/04/2021 13:13:28] Decoding beam search prediction ...\n",
      "[19/04/2021 13:13:28] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 13:13:28] Evaluating on metric sacrebleu\n",
      "[19/04/2021 13:13:29] Computing SacreBleu scores on the val split...\n",
      "[19/04/2021 13:13:29] Bleu_4: 0.16974079447720594\n",
      "[19/04/2021 13:13:30] Done evaluating on metric sacrebleu\n",
      "[19/04/2021 13:13:30] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_30.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/35\n",
      "282/282 [==============================] - 7179s 25s/step - loss: 3.6947 - perplexity: 6613.8262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 15:13:09] <<< Saving model to trained_models/tutorial_model/epoch_31 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 15:13:13] <<< Model saved >>>\n",
      "\n",
      "[19/04/2021 15:13:13] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 15:13:13] Starting dataLoad_process_0...\n",
      "[19/04/2021 15:13:13] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 15:13:14] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 28551.213783 \t Average cost: 12.689428\n",
      "The sampling took: 1212.008859 secs (Speed: 0.538671 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 15:33:26] Prediction output 0: target_text (text)\n",
      "[19/04/2021 15:33:26] Decoding beam search prediction ...\n",
      "[19/04/2021 15:33:26] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 15:33:26] Evaluating on metric sacrebleu\n",
      "[19/04/2021 15:33:27] Computing SacreBleu scores on the val split...\n",
      "[19/04/2021 15:33:27] Bleu_4: 0.17149315291046807\n",
      "[19/04/2021 15:33:27] Done evaluating on metric sacrebleu\n",
      "[19/04/2021 15:33:27] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_31.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/35\n",
      "282/282 [==============================] - 7053s 25s/step - loss: 3.6372 - perplexity: 6657.4019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 17:31:01] <<< Saving model to trained_models/tutorial_model/epoch_32 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 17:31:05] <<< Model saved >>>\n",
      "\n",
      "[19/04/2021 17:31:05] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 17:31:06] Starting dataLoad_process_0...\n",
      "[19/04/2021 17:31:06] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 17:31:06] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 28016.915329 \t Average cost: 12.451962\n",
      "The sampling took: 1202.770099 secs (Speed: 0.534564 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-132:\n",
      "[19/04/2021 17:51:09] Prediction output 0: target_text (text)\n",
      "Process Process-130:\n",
      "[19/04/2021 17:51:09] Decoding beam search prediction ...\n",
      "[19/04/2021 17:51:09] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 17:51:09] Evaluating on metric sacrebleu\n",
      "[19/04/2021 17:51:10] Computing SacreBleu scores on the val split...\n",
      "[19/04/2021 17:51:10] Bleu_4: 0.20793934813631812\n",
      "[19/04/2021 17:51:10] Done evaluating on metric sacrebleu\n",
      "[19/04/2021 17:51:10] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_32.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/35\n",
      "282/282 [==============================] - 7052s 25s/step - loss: 3.5886 - perplexity: 6765.9292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 19:48:42] <<< Saving model to trained_models/tutorial_model/epoch_33 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 19:48:47] <<< Model saved >>>\n",
      "\n",
      "[19/04/2021 19:48:47] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 19:48:47] Starting dataLoad_process_0...\n",
      "[19/04/2021 19:48:47] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 19:48:47] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 26825.546348 \t Average cost: 11.922465\n",
      "The sampling took: 1204.791657 secs (Speed: 0.535463 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-135:\n",
      "Process Process-136:\n",
      "[19/04/2021 20:08:52] Prediction output 0: target_text (text)\n",
      "[19/04/2021 20:08:52] Decoding beam search prediction ...\n",
      "[19/04/2021 20:08:52] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 20:08:52] Evaluating on metric sacrebleu\n",
      "[19/04/2021 20:08:53] Computing SacreBleu scores on the val split...\n",
      "[19/04/2021 20:08:53] Bleu_4: 0.19132937130888317\n",
      "[19/04/2021 20:08:53] Done evaluating on metric sacrebleu\n",
      "[19/04/2021 20:08:53] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_33.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/35\n",
      "282/282 [==============================] - 7110s 25s/step - loss: 3.5271 - perplexity: 6674.2905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 22:07:24] <<< Saving model to trained_models/tutorial_model/epoch_34 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 22:07:27] <<< Model saved >>>\n",
      "\n",
      "[19/04/2021 22:07:27] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 22:07:28] Starting dataLoad_process_0...\n",
      "[19/04/2021 22:07:28] Starting dataLoad_process_1...\n",
      "[19/04/2021 22:07:28] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 26738.033032 \t Average cost: 11.883570\n",
      "The sampling took: 1201.226783 secs (Speed: 0.533879 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-140:\n",
      "Process Process-139:\n",
      "[19/04/2021 22:27:29] Prediction output 0: target_text (text)\n",
      "[19/04/2021 22:27:29] Decoding beam search prediction ...\n",
      "[19/04/2021 22:27:29] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/04/2021 22:27:29] Evaluating on metric sacrebleu\n",
      "[19/04/2021 22:27:31] Computing SacreBleu scores on the val split...\n",
      "[19/04/2021 22:27:31] Bleu_4: 0.1916130666282077\n",
      "[19/04/2021 22:27:31] Done evaluating on metric sacrebleu\n",
      "[19/04/2021 22:27:31] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_34.jpg >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/35\n",
      "282/282 [==============================] - 7202s 26s/step - loss: 3.4624 - perplexity: 6665.6230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20/04/2021 00:27:33] <<< Saving model to trained_models/tutorial_model/epoch_35 ... >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20/04/2021 00:27:37] <<< Model saved >>>\n",
      "\n",
      "[20/04/2021 00:27:38] <<< Predicting outputs of val set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20/04/2021 00:27:39] Starting dataLoad_process_0...\n",
      "[20/04/2021 00:27:39] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2250  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20/04/2021 00:27:39] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2250/2250  -  ETA: 0s   \n",
      " Total cost: 26404.451814 \t Average cost: 11.735312\n",
      "The sampling took: 1191.649363 secs (Speed: 0.529622 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20/04/2021 00:47:30] Prediction output 0: target_text (text)\n",
      "[20/04/2021 00:47:30] Decoding beam search prediction ...\n",
      "[20/04/2021 00:47:30] Using heuristic 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20/04/2021 00:47:30] Evaluating on metric sacrebleu\n",
      "[20/04/2021 00:47:31] Computing SacreBleu scores on the val split...\n",
      "[20/04/2021 00:47:31] Bleu_4: 0.208740137909648\n",
      "[20/04/2021 00:47:31] Done evaluating on metric sacrebleu\n",
      "[20/04/2021 00:47:31] \n",
      "<<< Progress plot saved in trained_models/tutorial_model/epoch_35.jpg >>>\n",
      "[20/04/2021 00:47:33] <<< Finished training model >>>\n"
     ]
    }
   ],
   "source": [
    "nmt_model.trainNet(dataset, training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "knMMNtC_NiGZ"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hq3_MyX3A4XV"
   },
   "source": [
    "## 3. Decoding with a trained Neural Machine Translation Model\n",
    "\n",
    "Now, we'll load from disk the model we just trained and we'll apply it for translating new text. In this case, we want to translate the 'test' split from our dataset.\n",
    "\n",
    "Since we want to translate a new data split ('test') we must add it to the dataset instance, just as we did before (at the first tutorial). In case we also had the refences of the test split and we wanted to evaluate it, we can add it to the dataset. Note that this is not mandatory and we could just predict without evaluating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFmG3Y5_d-1c"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "2H-jXRq4BGm_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20/04/2021 05:37:24] \tApplying tokenization function: \"tokenize_none\".\n",
      "[20/04/2021 05:37:24] Loaded \"test\" set inputs of data_type \"text\" with data_id \"source_text\" and length 2500.\n",
      "[20/04/2021 05:37:24] Loaded \"test\" set inputs of data_type \"ghost\" with data_id \"state_below\" and length 2500.\n",
      "[20/04/2021 05:37:24] Loaded \"test\" set inputs of type \"file-name\" with id \"raw_source_text\".\n"
     ]
    }
   ],
   "source": [
    "dataset.setInput('x_test.txt',\n",
    "            'test',\n",
    "            type='text',\n",
    "            id='source_text',\n",
    "            pad_on_batch=True,\n",
    "            tokenization=tokenize_x,\n",
    "            fill='end',\n",
    "            max_text_len=x_max_text_len,\n",
    "            min_occ=0)\n",
    "\n",
    "dataset.setInput(None,\n",
    "            'test',\n",
    "            type='ghost',\n",
    "            id='state_below',\n",
    "            required=False)\n",
    "\n",
    "dataset.setRawInput('x_test.txt',\n",
    "              'test',\n",
    "              type='file-name',\n",
    "              id='raw_source_text',\n",
    "              overwrite_split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUZveIgLCzlq"
   },
   "source": [
    "Now, let's load the translation model. Suppose we want to load the model saved at the end of the epoch 4:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "id": "8hgOSknZC2lh",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'coding_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-07ea47e15bad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mnmt_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoding_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'trained_models/tutorial_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mepoch_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'coding_dir' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-07ea47e15bad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mepoch_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mnmt_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoding_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'trained_models/tutorial_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_load\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'coding_dir' is not defined"
     ]
    }
   ],
   "source": [
    "params['INPUT_VOCABULARY_SIZE'] = dataset.vocabulary_len[params['INPUTS_IDS_DATASET'][0]]\n",
    "params['OUTPUT_VOCABULARY_SIZE'] = dataset.vocabulary_len[params['OUTPUTS_IDS_DATASET'][0]]\n",
    "\n",
    "# Load model\n",
    "#n_epochs\n",
    "# epoch_load = -1\n",
    "# try:\n",
    "#   nmt_model = loadModel(os.path.join(coding_dir,'trained_models/tutorial_model'),n_epochs)\n",
    "#   epoch_load = n_epochs\n",
    "# except:\n",
    "#   epoch_load = 10\n",
    "#   nmt_model = loadModel(os.path.join(coding_dir,'trained_models/tutorial_model'),epoch_load)\n",
    "\n",
    "nmt_model = loadModel('trained_models/tutorial_model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piDc_y0pC5la"
   },
   "source": [
    "Once we loaded the model, we just have to invoke the sampling method (in this case, the Beam Search algorithm) for the 'test' split:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "2FBT1HWYC9ip"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[20/04/2021 05:40:01] <<< Predicting outputs of test set >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20/04/2021 05:40:23] Starting dataLoad_process_0...\n",
      "[20/04/2021 05:40:23] Starting dataLoad_process_1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1/2500  -  ETA: -1s \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20/04/2021 05:40:23] Starting dataLoad_process_2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 2500/2500  -  ETA: 0s   \n",
      " Total cost: 29296.265267 \t Average cost: 11.718506\n",
      "The sampling took: 1251.536527 secs (Speed: 0.500615 sec/sample)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-147:\n"
     ]
    }
   ],
   "source": [
    "is_transformer = params.get('ATTEND_ON_OUTPUT', 'transformer' in params['MODEL_TYPE'].lower())\n",
    "\n",
    "params_prediction = {\n",
    "    'language': 'en',\n",
    "    'tokenize_f': eval('dataset.' + tokenize_x),\n",
    "    'beam_size': beam_size,\n",
    "    'optimized_search': True,\n",
    "    'model_inputs': params['INPUTS_IDS_MODEL'],\n",
    "    'model_outputs': params['OUTPUTS_IDS_MODEL'],\n",
    "    'dataset_inputs':  params['INPUTS_IDS_DATASET'],\n",
    "    'dataset_outputs':  params['OUTPUTS_IDS_DATASET'],\n",
    "    'n_parallel_loaders': n_parallel_loaders,\n",
    "    'maxlen': y_max_text_len,\n",
    "    'normalize_probs': True,\n",
    "    'pos_unk': True and not is_transformer,\n",
    "    'heuristic': 0,\n",
    "    'state_below_maxlen': -1,\n",
    "    'predict_on_sets': ['test'],\n",
    "    'verbose': 0,\n",
    "    'attend_on_output': is_transformer\n",
    "  }\n",
    "predictions = nmt_model.predictBeamSearchNet(dataset, params_prediction)['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2JcEpFJDTDs"
   },
   "source": [
    "Up to now, in the variable 'predictions', we have the indices of the words of the hypotheses. We must decode them into words. For doing this, we'll use the dictionary stored in the dataset object:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "4EGTAOFXDYLX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20/04/2021 06:00:54] Decoding beam search prediction ...\n"
     ]
    }
   ],
   "source": [
    "from keras_wrapper.utils import decode_predictions_beam_search\n",
    "vocab = dataset.vocabulary['target_text']['idx2words']\n",
    "samples = predictions['samples'] # Get word indices from the samples.\n",
    "\n",
    "predictions = decode_predictions_beam_search(samples,  \n",
    "                                             vocab,\n",
    "                                             verbose=params['VERBOSE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MZVhj0IDd93"
   },
   "source": [
    "Finally, we store the hypotheses:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "kznqPYZMDg8o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create a dictionary of jobs for each anaconda network\n",
      "check if the given field is present in the\n",
      "create a new image with a given detail object\n",
      "return a list of tuples of legacy name\n",
      "return the list of items from the given task\n",
      "test the test method\n",
      "compute the logistic loss of heterostructure\n",
      "tests that the is returned for the same test\n",
      "check if the given field is not in the\n",
      "salt reply role\n",
      "return the next interval for the current position\n",
      "create a new instance of the depot profile this\n",
      "initialize the sensor\n",
      "create a new request for a hybrid connection param\n",
      "get the cups in the given task and check\n",
      "create a z3 expression expression self other other y\n",
      "returns the value of the attribute\n",
      "param str path the file path\n",
      "sets the bcd encoded addr\n",
      "return the bass pitch class of the chord figure\n"
     ]
    }
   ],
   "source": [
    "filepath = 'test.pred'\n",
    "from keras_wrapper.extra.read_write import list2file\n",
    "list2file(filepath, predictions)\n",
    "!head -n 20 test.pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUntF5T6Dx2w"
   },
   "source": [
    "If we have the references of this split, we can also evaluate the performance of our system on it. First, we must add them to the dataset object:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "-pccriZWDyqr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20/04/2021 06:00:58] \tApplying tokenization function: \"tokenize_none\".\n",
      "[20/04/2021 06:00:58] Loaded \"test\" set outputs of data_type \"text\" with data_id \"target_text\" and length 2500.\n",
      "[20/04/2021 06:00:58] Keeping 1 captions per input on the test set.\n",
      "[20/04/2021 06:00:58] Samples reduced to 2500 in test set.\n"
     ]
    }
   ],
   "source": [
    "dataset.setOutput('y_test.txt',\n",
    "             'test',\n",
    "             type='text',\n",
    "             id='target_text',\n",
    "             pad_on_batch=True,\n",
    "             tokenization=tokenize_y,\n",
    "             sample_weights=True,\n",
    "             max_text_len=y_max_text_len,\n",
    "             max_words=y_max_words)\n",
    "keep_n_captions(dataset, repeat=1, n=1, set_names=['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class model:\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "\n",
    "    def apply(self, x):\n",
    "        for i in tqdm(range(30)):\n",
    "            time.sleep(1)\n",
    "        clear_output(wait=True)\n",
    "        print('Comments generated!')\n",
    "\n",
    "model = model('nmt', 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'double the inputted value'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riPUDl-xD1WM"
   },
   "source": [
    "Next, we call the evaluation system: the sacreBLEU package:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "rfLzm4QBD2oj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20/04/2021 06:01:00] Computing SacreBleu scores on the test split...\n",
      "[20/04/2021 06:01:00] Bleu_4: 0.23424182354792403\n"
     ]
    }
   ],
   "source": [
    "from keras_wrapper.extra.evaluation import select\n",
    "metric = 'sacrebleu'\n",
    "# Apply sampling\n",
    "extra_vars = dict()\n",
    "extra_vars['tokenize_f'] = eval('dataset.' + tokenize_x)\n",
    "extra_vars['language'] = params['TRG_LAN']\n",
    "extra_vars['test'] = dict()\n",
    "extra_vars['test']['references'] = dataset.extra_variables['test']['target_text']\n",
    "metrics = select[metric](pred_list=predictions,\n",
    "                                          verbose=1,\n",
    "                                          extra_vars=extra_vars,\n",
    "                                          split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "id": "eTujympHCA2h",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wandb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-954ca6922065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'BLEU_4_TEST'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Bleu_4'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'wandb' is not defined"
     ]
    }
   ],
   "source": [
    "wandb.log({'BLEU_4_TEST': metrics['Bleu_4']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g1HyOXCiaMFW",
    "outputId": "04e8f290-447b-4bbe-dc0b-4967082b72b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['create a dictionary of jobs for each anaconda network',\n",
       " 'check if the given field is present in the',\n",
       " 'create a new image with a given detail object',\n",
       " 'return a list of tuples of legacy name',\n",
       " 'return the list of items from the given task',\n",
       " 'test the test method',\n",
       " 'compute the logistic loss of heterostructure',\n",
       " 'tests that the is returned for the same test',\n",
       " 'check if the given field is not in the',\n",
       " 'salt reply role',\n",
       " 'return the next interval for the current position',\n",
       " 'create a new instance of the depot profile this',\n",
       " 'initialize the sensor',\n",
       " 'create a new request for a hybrid connection param',\n",
       " 'get the cups in the given task and check',\n",
       " 'create a z3 expression expression self other other y',\n",
       " 'returns the value of the attribute',\n",
       " 'param str path the file path',\n",
       " 'sets the bcd encoded addr',\n",
       " 'return the bass pitch class of the chord figure',\n",
       " 'calculate the noise ceiling for each function usually of',\n",
       " 'compute the multinomial vectors of f and g for',\n",
       " 'client user rucio download',\n",
       " 'this function creates a new macvlan network for a',\n",
       " 'test the retr method',\n",
       " 'check if the given field is not a single',\n",
       " 'create a new network with a file',\n",
       " 'test the calculation of the method of the test',\n",
       " 'object a list of items from the chewie profile',\n",
       " 'return the current state of the current state',\n",
       " 'update the current state',\n",
       " 'returns the value of name is a tax tax',\n",
       " 'return the list of jobs in the elasticsearch directory',\n",
       " 'create a new controller',\n",
       " 'create a z3 expression of the given domain name',\n",
       " 'get the current audio file into a file file',\n",
       " 'test formlist xform hybrid test page succeeds',\n",
       " 'return the leading monomial of f in sympy import',\n",
       " 'returns the list of items from the chewie ns',\n",
       " 'returns the leading distance for the moment matrix',\n",
       " 'get a single value from the i2c value',\n",
       " 'test that upload works properly with expected and timestamps',\n",
       " 'this function is used to compare the realization of',\n",
       " 'compute the moment of the heterostructure',\n",
       " 'return the list of selectors',\n",
       " 'returns the leading monomial of f from sympy import',\n",
       " 'sets the spacing of the indicator param axis the',\n",
       " 'returns the list of jobs and return the extracted',\n",
       " 'test the kgtk download and download dates',\n",
       " 'test the flowdurationcurvedeviationrecorder',\n",
       " 'test the essential data tagging rule',\n",
       " 'l l memcacheprotocol getmultiple is a l plating wigeted',\n",
       " 'get the current value from the current config',\n",
       " 'return a list of tuples of repr',\n",
       " 'get the data from the given task and return',\n",
       " 'check if the provided item is valid in the',\n",
       " 'returns the leading distance of the moment matrix matrix',\n",
       " 'check that the given field is valid to the',\n",
       " 'return the value of the value of the given',\n",
       " 'create a list of participants recent files',\n",
       " 'tests the get negated terms method',\n",
       " 'return a dictionary of all sites between the rate',\n",
       " 'returns a tensor of the tensor in the tensor',\n",
       " 'test the skeleton introduced',\n",
       " 'create a new instance of a hybrid class param',\n",
       " 'test api auth auth auth auth auth auth auth',\n",
       " 'create a new recent file',\n",
       " 'get a list of recids from vmanage',\n",
       " 'get the cups in the given task path param',\n",
       " 'get the cups in the chewie getheader 3',\n",
       " 'returns the undirected number of zeros in the z3',\n",
       " 'returns the unaltered replaced between a dns',\n",
       " 'return the leading monomial of f from sympy import',\n",
       " 'this function accepts the participants function',\n",
       " 'return the list of available nodes in the form',\n",
       " 'test the precision distance on two pixels',\n",
       " 'test the logoff tagging rule',\n",
       " 'this function creates a new macvlan network for a',\n",
       " 'create a new xml object with a list of',\n",
       " 'compute the loss of zeros in the given finite',\n",
       " 'test the getting state of light',\n",
       " 'compute the moment of the heterostructure',\n",
       " 'test the creation of a simple xlsxwriter file',\n",
       " 'create a new polynomial between f and g between',\n",
       " 'set the current state of the model',\n",
       " 'set the current state of the subscription',\n",
       " 'test that the generated of the same test jira',\n",
       " 'return the value of the current tax icrs j2000',\n",
       " 'test the skeleton of a circle',\n",
       " 'returns the name of the name of the name',\n",
       " 'test wikipedia talk main page on enws is namespace',\n",
       " 'check if the given field is not in the',\n",
       " 'return the number of free nodes in the object',\n",
       " 'test the functionality of a simple xlsxwriter file with',\n",
       " 'test that the circuit hashes of identical circuits except',\n",
       " 'test that the circuit hashes of identical circuits except',\n",
       " 'test the kgtk compact processor',\n",
       " 'test the test function',\n",
       " 'this function is used to create a decorator with',\n",
       " 'test plotting data',\n",
       " 'test api auth qasm of a naive case',\n",
       " 'unregister the model and restart the model is larger',\n",
       " 'create a list of jobs from the s3 config',\n",
       " 'this function creates a list of extractions and 20',\n",
       " 'returns the roster modules',\n",
       " 'floating point wavenumber point bit',\n",
       " 'test the fpga network',\n",
       " 'return a list of items from the api api',\n",
       " 'get a list of files from the api serializable',\n",
       " 'return the bass pitch job of the remaining table',\n",
       " 'get a list of files from the api graph',\n",
       " 'return the list of items in the given task',\n",
       " 'test the arc2d scale method',\n",
       " 'create a new mediaitem',\n",
       " 'create a list of combinations of readers to be',\n",
       " 'test api auth user with namespace',\n",
       " 'returns a list of ibisgroup objects from a lobid',\n",
       " 'sends a request to the api client',\n",
       " 'test posynomial construction',\n",
       " 'returns the list of items from the given task',\n",
       " 'check that the opmkeyw job is defined in the',\n",
       " 'test the calculation of party',\n",
       " 'create a new object that can be used for',\n",
       " 'return a list of strings from the s3 file',\n",
       " 'get the cups in the chewie getheader target participant',\n",
       " 'return the number of layers of the fitnesses in',\n",
       " 'get the number of readers to return the format',\n",
       " 'compute the logistic loss matrix with inertia the image',\n",
       " 'this function creates a new network set from the',\n",
       " 'return a list of views',\n",
       " 'test setting up a single workbook',\n",
       " 'return the value of the attribute',\n",
       " 'test deleting the test table',\n",
       " 'test the calculation of the network s interface and',\n",
       " 'wpf bool py str wpf int id id str',\n",
       " 'get a list of files from the api manager',\n",
       " 'return the list of occupied com readers the str',\n",
       " 'get the current state of the database',\n",
       " 'set the current state of the current db',\n",
       " 'create a list of beams',\n",
       " 'return the list of items for the given task',\n",
       " 'return a list of tuples of gocdb that are',\n",
       " 'estimation of mins in the heterostructure',\n",
       " 'check that the opmkeyw file is present in the',\n",
       " 'create a new syncgroup object param str name the',\n",
       " 'create a new request for gssapi',\n",
       " 'construct a new ibisperson from the given goal if',\n",
       " 'return the list of items from the given task',\n",
       " 'return true if the value is not either',\n",
       " 'delete a new network with specified file and appends',\n",
       " 'test api auth saving and write',\n",
       " 'returns the unaltered geometry of the image and the',\n",
       " 'return a list of lists of the input expression',\n",
       " 'return the leading term of f by b g',\n",
       " 'calculate the rotation estimates the rotation estimates the rotation',\n",
       " 'create a new mediaitem of the given type',\n",
       " 'test to create a simple test of the data',\n",
       " 'get the cups in the given task param broker',\n",
       " 'set the value of the given type param list',\n",
       " 'create a new mediaitem of the given dictionnary and',\n",
       " 'initializes initializes a new httpbackend object with values from',\n",
       " 'create a new object from a dictionary',\n",
       " 'test the skeleton introduced',\n",
       " 'return true if the given field is not either',\n",
       " 'create a new mediaitem of the specified subscription of',\n",
       " 'compute the moment of the heterostructure',\n",
       " 'test the kgtk compact simple workbook',\n",
       " 'create a list of participants of the taxlot and',\n",
       " 'gss api client wpf object',\n",
       " 'initializer of the protectionsourcetreeinfo class',\n",
       " 'return the current state of the current profile',\n",
       " 'returns the unaltered more intervals of the jobs for',\n",
       " 'returns the unaltered geometry of the given format and',\n",
       " 'plots the image of the heterostructure',\n",
       " 'create a new network with a specified file',\n",
       " 'check if the given path is not in the',\n",
       " 'returns the leading monomial of f from sympy import',\n",
       " 'test simple dice energies to initalization of dice dice',\n",
       " 'check if the given user is a valid pregnancy',\n",
       " 'get a list of radiance strings from a dictionary',\n",
       " 'get the current data from the current language',\n",
       " 'return a list of jobs for creating the signature',\n",
       " 'test api auth download dates',\n",
       " 'return the matching mavlink object',\n",
       " 'returns the unaltered more characters for the given task',\n",
       " 'create a simple layer with a simple sample',\n",
       " 'check if the given value is valid in the',\n",
       " 'create a list of beams constants and list of',\n",
       " 'get the imagemagick network rule',\n",
       " 'create a list of beams for a given night',\n",
       " 'return the leading distance for the moment of gaussian',\n",
       " 'return the list of items for the given task',\n",
       " 'return the current state',\n",
       " 'estimation of mins',\n",
       " 'compute the moment of f using the given gaussian',\n",
       " 'test that capillary msidset can be added to gaswater',\n",
       " 'test the calculation of a simple network with a',\n",
       " 'test multiplication with tapering',\n",
       " 'check if the given field is a valid value',\n",
       " 'calibrate pressure',\n",
       " 'compute the discrete discrete discrete lw param astropy class',\n",
       " 'get the current data from the current language type',\n",
       " 'return the current state of the current state',\n",
       " 'delete a role',\n",
       " 'create a new image with a given connected object',\n",
       " 'param str path the str path to the api',\n",
       " 'test that we can add a submission with a',\n",
       " 'test that the user validation are correctly correctly',\n",
       " 'compute the moment of f by g param q',\n",
       " 'returns the list of trainable objects whose views can',\n",
       " 'test the existence of opensearch startindex',\n",
       " 'test that the circuit hashes of identical circuits except',\n",
       " 'test plotting data',\n",
       " 'gets the request for the specified connection param name',\n",
       " 'test that we can add a submission reviews',\n",
       " 'return a list of jobs',\n",
       " 'test for bug over uid',\n",
       " 'create the z3 expression other self other other other',\n",
       " 'initializes a new samp hub object',\n",
       " 'create a new file with a given file param',\n",
       " 'return the list of items of the current domain',\n",
       " 'create a new polynomial between f from x poly',\n",
       " 'return the list of jobs from the elasticsearch if',\n",
       " 'test test topomap heal test',\n",
       " 'create a new instance of a given bucket param',\n",
       " 'compute the logistic loss matrix and calculate sigmoid layer',\n",
       " 'test that the test hashes works are correctly t',\n",
       " 'create a list of beams from the input of',\n",
       " 'returns the unaltered replaced for a single format and',\n",
       " 'return the value of the given type',\n",
       " 'returns the list of jobs for the given task',\n",
       " 'get a list of readers to be able to',\n",
       " 'this function is used to decode a list of',\n",
       " 'check if the given path is a valid pregnancy',\n",
       " 'create a new network object from a list of',\n",
       " 'return a list of items from the current current',\n",
       " 'return the restriction of the given type if it',\n",
       " 'test that the rbac rule',\n",
       " 'this function is used to compare the words by',\n",
       " 'set the given network param profile list of keyword',\n",
       " 'check if the given field is not present in',\n",
       " 'return the number of days for the given distribution',\n",
       " 'set the current state of the subscription',\n",
       " 'return a list of all nodes in the database',\n",
       " 'returns the roster series',\n",
       " 'this function is aimed to decode a single function',\n",
       " 'check if the given model is not found',\n",
       " 'create a dictionary of combinations of readers to create',\n",
       " 'creates a new shot workspace for setting of the',\n",
       " 'check whether the job is loaded for the case',\n",
       " 'return a dictionary of all packages names of the',\n",
       " 'this function calculates the sky training loss and plot',\n",
       " 'compute the moment matrix of f using sympy import',\n",
       " 'test that the work of kubernetes parameters are handled',\n",
       " 'return the value of the currently selected item',\n",
       " 'test that pkgfmt test formats works as expected',\n",
       " 'check if the censor can be added to the',\n",
       " 'test for deleting the given data',\n",
       " 'returns a list of jobs from a given file',\n",
       " 'get the data of the given task and check',\n",
       " 'test the calculation of the model produced',\n",
       " 'create a new request for a hybrid connection param',\n",
       " 'this function is used to compare the brightest object',\n",
       " 'returns the roster flow with given task and annotation',\n",
       " 'constructor for the subprocess the model model this method',\n",
       " 'check if the explanation runs trying to the role',\n",
       " 'test sortedset functionality',\n",
       " 'return the number of days for the given state',\n",
       " 'create a new image object from the current state',\n",
       " 'create a new image with a given bucket param',\n",
       " 'returns a list of radiance of pod whose s',\n",
       " 'test the kgtk compact processor',\n",
       " 'test the existence of party and author',\n",
       " 'create a new instance of the given object',\n",
       " 'return the value of the indices for the given',\n",
       " 'test the kgtk compact simple gromacs data',\n",
       " 'test the parser',\n",
       " 'param str path the name to the channel param',\n",
       " 'check if the given task is not present in',\n",
       " 'test the arc2d subdivide algorithm',\n",
       " 'returns a list of cups',\n",
       " 'return a list of ascii of f from',\n",
       " 'create a new presoview leave curviews unset',\n",
       " 'gets the request for a given request param str',\n",
       " 'return a list of data constants',\n",
       " 'return the list of items from the given task',\n",
       " 'param bool the callable api',\n",
       " 'get a new network configuration from a file',\n",
       " 'create a new network with a list of complexmodels',\n",
       " 'test api auth initialisation',\n",
       " 'return the leading monomial of f in sympy import',\n",
       " 'test the existence of opensearch quickadd',\n",
       " 'create a new mediaitem of the given task',\n",
       " 'create a new instance of the given network and',\n",
       " 'get the value of the given value of a',\n",
       " 'compute the moment of sight xrf coordinates from 3d',\n",
       " 'returns the number of days for each item in',\n",
       " 'test that capillary hashes are correctly correctly manually',\n",
       " 'return the current state of the current state',\n",
       " 'test ability to ensure the createbatchrecipes test of the',\n",
       " 'return the pitch expression in the remaining string',\n",
       " 'test that capillary pressure can be added to gaswater',\n",
       " 'return a list of selectors and return the signature',\n",
       " 'returns the value of the given type',\n",
       " 'creates a new network with a given config object',\n",
       " 'tests the getting network configurations for the reservoir',\n",
       " 'get a single redis object from a redis object',\n",
       " 'return the number of available nodes in the object',\n",
       " 'compute the logistic loss of xrf model summarizes the',\n",
       " 'get the given value of the given timestamp',\n",
       " 'test the numpyarraydailyprofileparameterrecorder',\n",
       " 'set the noise param profile type object',\n",
       " 'test that the test hashes of identical circuits are',\n",
       " 'return the current current file for the current file',\n",
       " 'test the existence of party objects',\n",
       " 'return true if the current character is a list',\n",
       " 'get the current tax',\n",
       " 'test that the documented ix is produced correctly',\n",
       " 'test that the user ixp call works correctly',\n",
       " 'test the fpga network',\n",
       " 'create a new polynomial on a 3d object',\n",
       " 'return a dictionary of module names for the module',\n",
       " 'parser for www fringeoctopus com',\n",
       " 'return the number of days that are not been',\n",
       " 'compute the multinomial vectors of vectors',\n",
       " 'test that the validation is raised if the case',\n",
       " 'return the number of cpus and debye in the',\n",
       " 'proxy function to get distinctivness class networkinterface param str',\n",
       " 'test that when the user invoking kubernetes works',\n",
       " 'returns the leading monomial of f in sympy import',\n",
       " 'get the number of bytes of the given object',\n",
       " 'sets the spacing of the given model for this',\n",
       " 'test the creation of a simple workbook',\n",
       " 'compute the logistic xrf model with derechos param qinit',\n",
       " 'return a dictionary of jobs for creating the files',\n",
       " 'test the creation of a simple xlsxwriter file',\n",
       " 'test test topomap rm test',\n",
       " 'return the restriction of the item',\n",
       " 'create a new mediaitem with a given path if',\n",
       " 'test the calculation of the network daemon',\n",
       " 's33 lattice',\n",
       " 'test that the user is not a network s',\n",
       " 'compute the moment of zeros in the heterostructure',\n",
       " 'test the reading of the trace header 3',\n",
       " 'set the current state of the cs',\n",
       " 'test that capillary pressure can be added for a',\n",
       " 'check if the given path is a valid string',\n",
       " 'create a new mediaitem of the specified task',\n",
       " 'return a list of jobs for creating the included',\n",
       " 'return a list of tuples of subsys string',\n",
       " 'assert that the ges element has a certain checksum',\n",
       " 'compute the moment matrix of the heterostructure',\n",
       " 'return a list of items for the current domain',\n",
       " 'this function will delete a new anaconda object',\n",
       " 'returns the matching descendent',\n",
       " 'test that the msidset can be placed in the',\n",
       " 'create a list of tables in the database',\n",
       " 'return the list of items from the current subscription',\n",
       " 'test that the circuit hashes of identical circuits except',\n",
       " 'initializes a new httpbackend object with values from keyword',\n",
       " 'return a list of tuples of the current network',\n",
       " 'test the creation of a simple workbook with',\n",
       " 'returns the list of jobs from the apk',\n",
       " 'handle the model for the dock function for the',\n",
       " 'check if the given path is a valid string',\n",
       " 'return the list of items in the given task',\n",
       " 'create a new keras class and keras keras class',\n",
       " 'test the essential workbook method',\n",
       " 'test that we can add a multi language redshift',\n",
       " 'compute the logistic xrf model model param target model',\n",
       " 'return the excluded of the given value for the',\n",
       " 'test that capillary multiples are correctly',\n",
       " 'this function is used to compare the data s',\n",
       " 'is a new image from the ndk file and',\n",
       " 'test the creation of a simple xlsxwriter file with',\n",
       " 'return a dictionary of all packages names of the',\n",
       " 'create a new request for a hybrid class param',\n",
       " 'calculate the levenshtein for the given diagonal nearest',\n",
       " 'test ability to ensure that we can find a',\n",
       " 'return a list of all nodes in the object',\n",
       " 'create a new xml object from the given file',\n",
       " 'create a new mediaitem and return it for a',\n",
       " 'creates a new object for the specified subscription',\n",
       " 'estimation of mins',\n",
       " 'get the request for the specified database',\n",
       " 'returns the unaltered filtered to the file',\n",
       " 'return the value of the current surname',\n",
       " 'test whether the class is caught if there is',\n",
       " 'create a new mediaitem of the specified task',\n",
       " 'test the creation of a simple workbook with 6',\n",
       " 'check if the ges element is a certain object',\n",
       " 'test the fpga network',\n",
       " 'compute the multinomial transformation moment of inertia and the',\n",
       " 'create a new mediaitem of the specified task',\n",
       " 'test with deprecated 8 filtered a namespace 1 testing',\n",
       " 'test deleting a build rule',\n",
       " 'test the creation of a simple xlsxwriter file with',\n",
       " 'test the arc2d subdivide methods',\n",
       " 'create a new mediaitem of the specified subscription',\n",
       " 'create a list of tuples of the gives the',\n",
       " 'test the flowdurationcurvedeviationrecorder',\n",
       " 'test the fpga network',\n",
       " 'test the creation of a simple xlsxwriter file with',\n",
       " 'returns the pagerank of the derivatives',\n",
       " 'test the functionality',\n",
       " 'compute the multinomial vectors of vectors',\n",
       " 'test the existence of gcal quickadd',\n",
       " 'returns the unaltered more entropy to the specified language',\n",
       " 'easy to the promise of the given samp hub',\n",
       " 'return a list of lists of the finite network',\n",
       " 'test the main method',\n",
       " 'return a dictionary of selectors',\n",
       " 'check if the given path is a valid or',\n",
       " 'return the current tax value if the current name',\n",
       " 'test apertures phasescreens phasescreenlists and phasescreenpsfs are correctly can',\n",
       " 'searches for approval the orcid',\n",
       " 'returns the list of items in the given task',\n",
       " 'create a new network with a new broker param',\n",
       " 'iterator over the undo samp hub object dragging utilities',\n",
       " 'return a list of network sites by their values',\n",
       " 'returns a list of free characters for the given',\n",
       " 'qt slot copyavailable state of user editor changed',\n",
       " 'get the current current file',\n",
       " 'create a new image with a given psf object',\n",
       " 'set the current state of the cs',\n",
       " 'return the number of jobs in the class',\n",
       " 'this function is used to compare the brightest object',\n",
       " 'test the calculation of a simple circle in the',\n",
       " 'check if the provided item is valid in the',\n",
       " 'test pixel array with normal bit distribution sample pixel',\n",
       " 'creates a new network object from a list of',\n",
       " 'test the retr method for the stor for the',\n",
       " 'get a userfcn to the specified file param str',\n",
       " 'test the calculation of party',\n",
       " 'compute the moment matrix of the heterostructure',\n",
       " 'get a list of radiance of pod in the',\n",
       " 'returns the unaltered timestamps to the given file',\n",
       " 'create a list of beams for each format',\n",
       " 'test the functionality',\n",
       " 'check if the value is not not present',\n",
       " 'get the given data to the chewie muxing list',\n",
       " 'set the noise level',\n",
       " 'returns the leading monomial of f in f poly',\n",
       " 'return the position of the current position in the',\n",
       " 'test the reading of the trace header 6',\n",
       " 'return the leading distance for f and g poly',\n",
       " 'test the existence of the atom published in the',\n",
       " 'test that the main page is clicked for comments',\n",
       " 'return the z3 expression representing the given value of',\n",
       " 'create a new network with a given language object',\n",
       " 'this function is used to create a reservoirquery with',\n",
       " 'creates a new instance of a hybrid class param',\n",
       " 'test that capillary pressure can be added for a',\n",
       " 'compute the logistic loss of xrf model param keras',\n",
       " 'update the current state',\n",
       " 'create a new image with a given data and',\n",
       " 'return a list of strings for a list of',\n",
       " 'return the number of simulation for this class',\n",
       " 'compute the multinomial vectors of vectors',\n",
       " 'test the calculation of the atom s distance for',\n",
       " 'compute the moment of inertia of the heterostructure',\n",
       " 'returns a list of radiance strings',\n",
       " 'create a new network with a given object or',\n",
       " 'test the kgtk compact simple gromacs dataset',\n",
       " 'test that the circuit is thrown when the circuit',\n",
       " 'test the creation of a simple xlsxwriter file',\n",
       " 'return true if there is a certain point3d or',\n",
       " 'return a list of occupied characters constants and the',\n",
       " 'returns the value of the current value',\n",
       " 'param bool the channel',\n",
       " 'return the string representation of the tax tax tax',\n",
       " 'gss api client wpf object',\n",
       " 'test the kgtk compact processor',\n",
       " 'return the number of days between a valid and',\n",
       " 'create a new app file',\n",
       " 'initializes the widget',\n",
       " 'test the calculation of the model and verifies the',\n",
       " 'test the calculation of a simple circle in the',\n",
       " 'returns the list of conversion nodes in the package',\n",
       " 'test that capillary shooting on few steps are in',\n",
       " 'return the value of the given type',\n",
       " 'test that capillary msidset are correctly properly',\n",
       " 'returns a list of threedgridqubits a string of threedgridqubits',\n",
       " 'get the data from a file',\n",
       " 'test the reading of the trace',\n",
       " 'test the kgtk compact function',\n",
       " 'test that the mic detect for comments for',\n",
       " 'compute the moment of inertia to the heterostructure',\n",
       " 'return the list of items from the given task',\n",
       " 'get the cups in the biocontainers network',\n",
       " 'test the fpga network with respect to select and',\n",
       " 'create a new file with a list of keyword',\n",
       " 'test the fpga network s client client client client',\n",
       " 'return the leading distance for the moment of gaussian',\n",
       " 'get the cups in the chewie getheader import config',\n",
       " 'return the z3 expression other self other int int',\n",
       " 'create a new gov file',\n",
       " 'this function is used to create the form of',\n",
       " 'create a list of participants of the taxlot and',\n",
       " 'return a list of all nodes for the existing',\n",
       " 'create a new file with a new app object',\n",
       " 'test the essential method',\n",
       " 'return the list of cpus and downstream the rows',\n",
       " 'set the given state and returns the signature and',\n",
       " 'param str str the name of the class param',\n",
       " 'test the kgtk compact processor',\n",
       " 'this function is used to compare the data for',\n",
       " 'test the arc2d subdivide methods',\n",
       " 'create a list of uuids that are created in',\n",
       " 'test the creation of a simple xlsxwriter file',\n",
       " 'create a stepchain workload for a simple network',\n",
       " 'client user rucio add experience',\n",
       " 'create a new object from the api api param',\n",
       " 'main routine',\n",
       " 'returns the list of items in the given type',\n",
       " 'compute the derivatives of the given model between a',\n",
       " 'return the value of the given type',\n",
       " 'calculate the given data of the given image object',\n",
       " 'build a stepchain workload for a bug with the',\n",
       " 'get the current value of the current current',\n",
       " 'return the number of free energy for this object',\n",
       " 'create a new network object with a list of',\n",
       " 'returns the list of items in the chewie getheader',\n",
       " 'param bool gss deleg schedulerdriver id',\n",
       " 'set the model for the given model and the',\n",
       " 'this function calculates the multinomial loss matrix f 0',\n",
       " 'test the functionality',\n",
       " 'test the existence of party and author',\n",
       " 'the shap class is used for the function',\n",
       " 'return the image of the standard resid',\n",
       " 'test that the circuit hashes of identical circuits except',\n",
       " 'client user test checks the functionality of the user',\n",
       " 'check the combination of the periodic statement w ns',\n",
       " 'check if the given field is already in the',\n",
       " 'test the existence of atom and setting of the',\n",
       " 'get a list of files from the elasticsearch directory',\n",
       " 'test that the main page is raised if the',\n",
       " 'return a list of jobs',\n",
       " 'this function is used to compare the brightest object',\n",
       " 'return a list of free characters for the given',\n",
       " 'returns the list of jobs from the chewie separated',\n",
       " 'test that the rbac rule',\n",
       " 'create a new rsedeterministictranslation with a new application object',\n",
       " 'returns the unaltered geometry of the exposure and the',\n",
       " 'return the list of items from the current path',\n",
       " 'test that when the provided account is present in',\n",
       " 'create a new mediaitem from the api api',\n",
       " 'attempts to compute the musical ea finds the mean',\n",
       " 'returns the leading monomial of f from sympy import',\n",
       " 'get a new network and return a list of',\n",
       " 'return the current state of the current state',\n",
       " 'test that the ges element has a checksum is',\n",
       " 'this function is used to create a list of',\n",
       " 'check if the given field is a valid object',\n",
       " 'test whether the elastic case masks is correctly work',\n",
       " 'compute the roi between directional xrf model wave',\n",
       " 'return the number of integer constants of integer in',\n",
       " 'test that setting the fields of the case is',\n",
       " 'create a new file with a list of state',\n",
       " 'returns the leading distance of the orbital matrix in',\n",
       " 'create a new presoview leave curviews unset unless it',\n",
       " 'test the nlst method in the test case',\n",
       " 'create a list of layers of each classes of',\n",
       " 'this function is aimed to compare scipy optimize phase',\n",
       " 'returns the list of items from the given task',\n",
       " 'sets the list of items in the given path',\n",
       " 'test the kgtk compact processor',\n",
       " 'get the request from the container',\n",
       " 'test for dot bounds',\n",
       " 'test that we can put a solvent ts in',\n",
       " 'write and read back e3mfgyr02 fastq to 93 if',\n",
       " 'get the current value of the given config and',\n",
       " 'test that the main page is changed',\n",
       " 'test the creation of a simple workbook',\n",
       " 'test that the main method is correctly',\n",
       " 'create a dictionary of jobs for creating the files',\n",
       " 'test deleting a build rule',\n",
       " 'return a dictionary of all nodes in the remaining',\n",
       " 'get a list of jobs to the api param',\n",
       " 'test the arc2d scale method',\n",
       " 'check if the censor can be added to the',\n",
       " 'returns a list of ids constants of lengths',\n",
       " 'return a list of items from the current file',\n",
       " 'gets the request for the specified task and delete',\n",
       " 'this function creates a new network set in the',\n",
       " 'check the trash model id',\n",
       " 'get a list of files from the specified service',\n",
       " 'test xblock let transcripts cannot be close if the',\n",
       " 'returns a random tensor of the redis hash with',\n",
       " 'create a new image with the current profile',\n",
       " 'check that the model is present in the case',\n",
       " 'test the login method',\n",
       " 'test setting of an entity workload vip',\n",
       " 'get the request to the api',\n",
       " 'test the kgtk compact processor',\n",
       " 'return a list of items from the given file',\n",
       " 'test the calculation of a simple workbook with test',\n",
       " 'type',\n",
       " 'this function is used for the multicompartmentmodel function accepts',\n",
       " 'compute the logistic loss of heterostructure',\n",
       " 'compute the size of the given position in the',\n",
       " 'get the list of bytes and their characters in',\n",
       " 'check if the given user is not only in',\n",
       " 'return the number of bytes of the current format',\n",
       " 'check if the given value is equal if it',\n",
       " 'test the fpga network',\n",
       " 'return the leading distance of f in f poly',\n",
       " 'sends a request for gssapi and call the command',\n",
       " 'this function is used to compare the layer on',\n",
       " 'test that the validation classy network can be found',\n",
       " 'checks if the given user is not not not',\n",
       " 'test that we can be applied with a codeblocks',\n",
       " 'return the leading monomial of f from sympy import',\n",
       " 'get a list of jobs to be possible to',\n",
       " 'test the fpga network',\n",
       " 'returns the request thread',\n",
       " 'test that the generated infrastructure is correctly with the',\n",
       " 'test the method',\n",
       " 'recursively pads the data from the given format and',\n",
       " 'sets the visibility of the dock object for the',\n",
       " 'returns the list of items from the given task',\n",
       " 'test the calculation of a simple network with a',\n",
       " 'calculate the image of the fov in deg and',\n",
       " 'create a stepchain workload that can be used for',\n",
       " 'create a new mediaitem with a given task name',\n",
       " 'test that the circuit hashes of identical circuits except',\n",
       " 'create a list of beams constants and target target',\n",
       " 'create a new instance of the given task and',\n",
       " 'returns the number of layers of the fitnesses in',\n",
       " 'compute the moment matrix of the heterostructure',\n",
       " 'returns the list of jobs for the tooltip publishes',\n",
       " 'get a list of jobs to the s3 file',\n",
       " 'get the current data from the current format',\n",
       " 'returns the value of the attribute',\n",
       " 'test api auth download dates',\n",
       " 'get a new container to the specified task param',\n",
       " 'test the kgtk compact simple gromacs data',\n",
       " 'compute polynomial quotient of f from sympy import sympy',\n",
       " 'compute the moment of zeros',\n",
       " 'test that the main page ixp successfully add a',\n",
       " 'parser for www fringeoctopus com',\n",
       " 'test the fpga network',\n",
       " 'test that the main method is correctly',\n",
       " 'test posynomial construction',\n",
       " 'parser for carospencerinvestigates blogspot com',\n",
       " 'this function is used to compare the jobs for',\n",
       " 'test the kgtk compact processor',\n",
       " 'test that capillary unpickle is correctly correctly',\n",
       " 'create a z3 expression representing the given domain name',\n",
       " 'return a list of selectors and return the format',\n",
       " 'test ability to ensure that we can add a',\n",
       " 'create a new polynomial between f in sympy import',\n",
       " 'create a z3 expression expression self other other 10',\n",
       " 'create a list of beams constants and str modules',\n",
       " 'return the current tax of the current domain',\n",
       " 'test the retr functionality in the assistant chandler method',\n",
       " 'return the list of items from the given task',\n",
       " 'test the calculation of the atom s distance for',\n",
       " 'test the creation of a simple workbook',\n",
       " 'check if the given field is not needed in',\n",
       " 'param bool the api api api param experience the',\n",
       " 'return a dictionary of json name and the attribute',\n",
       " 'get a list of files from the current item',\n",
       " 'callback when the editor is not having',\n",
       " 'populate the emboss gromacs pod autoscaler with the analysis',\n",
       " 'return the list of items for the given task',\n",
       " 'check that the given field is valid to the',\n",
       " 'check if the explanation runs mousemove sent and if',\n",
       " 'this function is used to compare the brightest of',\n",
       " 'tests the reading of the trace qubit terms',\n",
       " 'test that the test hashes of identical circuits are',\n",
       " 'create a new network id',\n",
       " 'check if the pdu is a certain tax value',\n",
       " 'create a new image with a given connected object',\n",
       " 'test the basic trace tagging rule',\n",
       " 'test that the basic trace works in inclined',\n",
       " 'this function is aimed to compare concatenation reviews',\n",
       " 'check if the given model is present in the',\n",
       " 'this function creates a new network update by having',\n",
       " 'get the cups in the given task param str',\n",
       " 'check the existence of party in the atom',\n",
       " 'creates a new instance of a given audio class',\n",
       " 'test the arc2d subdivide methods',\n",
       " 'test that the request successfully successfully returns a list',\n",
       " 'return true if the given path is a breezy',\n",
       " 'get the current annotations from the current state',\n",
       " 'create a new network with a file',\n",
       " 'create a new network with a list of participants',\n",
       " 'returns the list of tuples of the nationally a',\n",
       " 'test that the validation of the network works properly',\n",
       " 'create a dictionary of gocdb for each dictionnary in',\n",
       " 'initialize the roi with a model param amp param',\n",
       " 'initialize the model',\n",
       " 'return a list of ids for the attribute s',\n",
       " 'convert a list of bytes to the format format',\n",
       " 'create a new presoview leave curviews unset unless vina',\n",
       " 'return a list of all nodes in the object',\n",
       " 'test that we can add a submission via a',\n",
       " 'return the list of all available nodes in the',\n",
       " 'param bool the placeholder',\n",
       " 'return the list of items from the given task',\n",
       " 'create a new instance of a given object from',\n",
       " 'create a new dataframe of each experiment for the',\n",
       " 'create a new mediaitem',\n",
       " 'this function is used to compare the brightest of',\n",
       " 'test that the number of issues are correctly t',\n",
       " 'gets the list of characters in the given task',\n",
       " 'get the cups in the given task c alice',\n",
       " 'create a new image object from a list of',\n",
       " 'create a new xml file with a given mount',\n",
       " 'test setting up a simple test',\n",
       " 'test pixel array for little 32 bit 1 sample',\n",
       " 'test api auth login api api',\n",
       " 'test the existence of atom steps',\n",
       " 'write and read back e3mfgyr02 fastq fastq fastq 10',\n",
       " 'return a list of all rows of the input',\n",
       " 'return the z3 expression expression self other the float',\n",
       " 'initializes a new httpbackend object with values from keyword',\n",
       " 'tests the logoff tagging rule',\n",
       " 'return the list of all volumes in the task',\n",
       " 'return the list of directories from the current state',\n",
       " 'create a dictionary of jobs to create a dictionary',\n",
       " 'create a new object from the specified object',\n",
       " 'this function is aimed to compare the pp',\n",
       " 'this function is used to calculate the function of',\n",
       " 'returns the list of jobs for the specified subscription',\n",
       " 'returns the unaltered a single layer from the i2c',\n",
       " 'test of job ts absent',\n",
       " 'test that the main page hashes is correctly works',\n",
       " 'create a new network set from gcs',\n",
       " 'check if the given field is not in the',\n",
       " 'tests the calculation of the network s interface and',\n",
       " 'returns a tensor of the given value and get',\n",
       " 'return the number of occupied distributions on the ventilations',\n",
       " 'create a list of conversion objects in the class',\n",
       " 'set the current state of the container',\n",
       " 'test the flowdurationcurvedeviationrecorder',\n",
       " 'this function creates a new network update by having',\n",
       " 'rm test',\n",
       " 'returns a list of tags from the specified service',\n",
       " 'return the list of jobs for testing that are',\n",
       " 'create a stepchain workload for a narrow in the',\n",
       " 'test the retr method',\n",
       " 'param str path the model to be used to',\n",
       " 'create a simple polynomial of a simple sample',\n",
       " 'this function creates a new network with a textual',\n",
       " 'set the current state of the cs',\n",
       " 'this function is used to evaluate the brightest of',\n",
       " 'set the size of the given position in the',\n",
       " 'test that the circuit hashes of identical circuits except',\n",
       " 'return the list of items from the current task',\n",
       " 'return the leading distance for the moment matrix',\n",
       " 'sends a request for gssapi and call for the',\n",
       " 'return the number of layers of the given connected',\n",
       " 'test the infomax blowup blowup',\n",
       " 'return a list of directories from the current state',\n",
       " 'calculate the rotation estimates the rotation estimates the fov',\n",
       " 'test that saving a single output and the error',\n",
       " 'create a new presoview leave curviews unset',\n",
       " 'test the retr method',\n",
       " 'test the retr method for controllers',\n",
       " 'sets the spacing of the major minor of the',\n",
       " 'returns the unaltered transformation of f and g for',\n",
       " 'localized datetimefields act by 8 confirm 3',\n",
       " 'test that when an invalid image is thrown when',\n",
       " 'return a list of tuples of repr',\n",
       " 'create a dictionary of jobs for each application object',\n",
       " 'return the current state of the current state',\n",
       " 'check if the user is present in the case',\n",
       " 'test that when an invalid image is present in',\n",
       " 'check that the model has been curves the bounds',\n",
       " 'return the next path for the current path',\n",
       " 'compute the multinomial loss of vectors and return',\n",
       " 'return the list of cpus and downstream them for',\n",
       " 'test that the circuit hashes of identical circuits except',\n",
       " 'test the kgtk compact processor',\n",
       " 'this function creates a new macvlan network for a',\n",
       " 'get the imagemagick of the network s language',\n",
       " 'estimation of peaks from a gaussian distribution using x1',\n",
       " 'return a list of selectors',\n",
       " 'create a new audio file with a file',\n",
       " 'test that the circuit hashes of identical circuits except',\n",
       " 'gets the appliancedevicesnmpv3trapdestinations api client appliancedevicesnmpv3trapdestinations',\n",
       " 'create a dictionary of gocdb for each database',\n",
       " 'return a list of selectors',\n",
       " 'get the list of jobs from the chewie muxing',\n",
       " 'set the noise',\n",
       " 'get a list of jobs from the specified file',\n",
       " 'set the current state of the roi and the',\n",
       " 'test the retr method in cwd method',\n",
       " 'return the value of the given type',\n",
       " 'return the list of cpus and cpus the signature',\n",
       " 'test wikipedia talk main page on enws is namespace',\n",
       " 'create a new polynomial from a polynomial poly x',\n",
       " 'set the noise model',\n",
       " 'gss api client wpf object',\n",
       " 'pd pitch to the concentration',\n",
       " 'check if the censor can be added to the',\n",
       " 'test the fpga network',\n",
       " 'return the excluded terms of the recent network',\n",
       " 'set the current state of the cs',\n",
       " 'test the functionality of the updated species implementation of',\n",
       " 'create a new object for the specified database',\n",
       " 'test that we can add a reservoirquery with applied',\n",
       " 'returns the pagerank of the nodes in the function',\n",
       " 'create a list of beams from a list of',\n",
       " 'compute the moment of zeros in the heterostructure',\n",
       " 'test sortedset functionality',\n",
       " 'this function creates a new network param profile the',\n",
       " 'compute the moment of zeros in the given model',\n",
       " 'test that the circuit hashes of identical circuits except',\n",
       " 'this function is aimed to decode a confusion with',\n",
       " 'set the current state of the subscription',\n",
       " 'create a new image object from the input object',\n",
       " 'return the list of items from the i2c type',\n",
       " 'this function creates a new network set from the',\n",
       " 'test that the circuit hashes of identical circuits except',\n",
       " 'return a list of polynomials from f from sympy',\n",
       " 'returns the value of the attribute and the attribute',\n",
       " 'set the leds pod in the subscription param list',\n",
       " 'test the constraint',\n",
       " 'create a new audio file',\n",
       " 'test apertures phasescreens phasescreenlists and phasescreenpsfs are correctly can',\n",
       " 'client user rucio download',\n",
       " 'return the restriction of the given task or not',\n",
       " 'test that the issues in activate the engine',\n",
       " 'report',\n",
       " 'test the retr method for tribe objects',\n",
       " 'test the calculation of the typical',\n",
       " 'returns a list of free characters whose values is',\n",
       " 'returns the pagerank of the orbital of and timestamps',\n",
       " 'compute the incidence matrix of f the reprojection y1',\n",
       " 'return the list of all readers to the form',\n",
       " 'test that get a list of fields and the',\n",
       " 'return the leading distance for f and g x',\n",
       " 'return the list of selectors',\n",
       " 'test that we can add a polygons timestamps to',\n",
       " 'test the calculation of a light state',\n",
       " 'return a dictionary of selectors',\n",
       " 'this function is used to compare the words by',\n",
       " 'test sortedset construction function',\n",
       " 'returns the leading monomial of f in sympy import',\n",
       " 'test the flowdurationcurvedeviationrecorder',\n",
       " 'return the value of the given value',\n",
       " 'check that the input item is present in the',\n",
       " 'create a new mediaitem of the specified task param',\n",
       " 'param str model the model param str path the',\n",
       " 'return a list of strings from a dictionary',\n",
       " 'check the trash model analysis',\n",
       " 'this function is used to compare the brightest object',\n",
       " 'compute the moment of inertia of the heterostructure',\n",
       " 'create a list of jobs and return the signature',\n",
       " 'test the kgtk compact processor',\n",
       " 'delete the specified file param client connection connection param',\n",
       " 'create a new audio file',\n",
       " 'return true if the given is a string suitable',\n",
       " 'test the kgtk compact processor',\n",
       " 'test that the rbac test are correctly',\n",
       " 'create a list of beams constants',\n",
       " 'test if no valid lists is properly t not',\n",
       " 'test that diag are properly',\n",
       " 'test the test method',\n",
       " 'floating point wavenumber point bit',\n",
       " 'create a list of jobs from the chewie ns',\n",
       " 'return the z3 expression other self other the float',\n",
       " 'get the request from the database',\n",
       " 'return the value of the value of the subgroup',\n",
       " 'discover the singletonservice of the domain return a list',\n",
       " 'returns the list of all derivatives of the chewie',\n",
       " 'check if the given field is not either in',\n",
       " 'get the current data from the current audio file',\n",
       " 'returns the number of days between degrees',\n",
       " 'return the bass pitch point of the image and',\n",
       " 'returns the leading monomial of f from sympy import',\n",
       " 'check that the user does not exist for the',\n",
       " 'test the creation of af edifact patient id object',\n",
       " 'test the creation of the atom download and verifies',\n",
       " 'test the essential image method',\n",
       " 'get the current state of the database',\n",
       " 'test that we can add dates and timestamps in',\n",
       " 'test whether the filtered a single error is correctly',\n",
       " 'return the position of the current position in the',\n",
       " 'create a new polynomial from a dictionary',\n",
       " 'return the list of uuids that are needed in',\n",
       " 'calculate the moment of the heterostructure',\n",
       " 'returns the number of days that are present in',\n",
       " 'create a list of jobs to be used for',\n",
       " 'test the creation of a simple xlsxwriter file',\n",
       " 'test that we can add a web integer case',\n",
       " 'test the calculation of a simple workbook',\n",
       " 'return the list of items for the given class',\n",
       " 'return the current value of the current content',\n",
       " 'create a new object from the api api param',\n",
       " 'test that the user validation is correctly correctly',\n",
       " 'return the number of days for the given spots',\n",
       " 'create a list of mins and maxes of the',\n",
       " 'this function creates a new network update by it',\n",
       " 'qt slot called when the user is changed',\n",
       " 'create a list of jobs to return the mapping',\n",
       " 'gets the request for the specified task file param',\n",
       " 'return the list of cpus and their ascii and',\n",
       " 'return the list of items from the i2c type',\n",
       " 'test plotting data',\n",
       " 'test that the given value is returned over the',\n",
       " 'test the validation of the validation method works',\n",
       " 'test the existence of the atom activation test the',\n",
       " 'test for a simple submission with a hole',\n",
       " 'test the calculation of the part of the given',\n",
       " 'test the creation of the edifact rest test exception',\n",
       " 'return the restriction of the given path if it',\n",
       " 'get the specified network configuration for the given network',\n",
       " 'test the functionality of the kwik',\n",
       " 'create a new ibisgroup from a dictionary',\n",
       " 'test that the approx for comments for gaswater',\n",
       " 'compute the moment of inertia of the heterostructure',\n",
       " 'this function creates a new network with a new',\n",
       " 'test api auth reset command',\n",
       " 'test that the test hashes of identical circuits except',\n",
       " 'get the current alignment of bytes',\n",
       " 'get a list of jobs to the s3 config',\n",
       " 'create a new shot class with the given class',\n",
       " 'test that pkgfmt rule works',\n",
       " 'param bool the str',\n",
       " 'return a floating point free of zeros',\n",
       " 'test the train functionality',\n",
       " 'return the list of items in the given task',\n",
       " 'return the severity of the raspberry c int',\n",
       " 'returns the list of roots of f for the',\n",
       " 'check that the job thread returns true if the',\n",
       " 'test for bug from cassandra ns jira ticket cassandra',\n",
       " 'test the precision for an array of 8 ns',\n",
       " 'test ability to ensure that the input usecase cannot',\n",
       " 'test the tablesrecorder',\n",
       " 'test api auth login route',\n",
       " 'create a dictionary of combinations of readers to make',\n",
       " 'return the current tax of the current object',\n",
       " 'check if the given path is a valid string',\n",
       " 'return the bass pitch job of the job file',\n",
       " 'parser for carospencerinvestigates blogspot com',\n",
       " 'test the calculation of a simple workbook',\n",
       " 'test the calculation of party and methods',\n",
       " 'get a list of jobs to the s3 config',\n",
       " 'test the kgtk compact simple gromacs dataset',\n",
       " 'create a dictionary of combinations of readers to create',\n",
       " 'return the number of simulation for this expression in',\n",
       " 'test the calculation of a simple network with a',\n",
       " 'test that the checksum is computed for grade cells',\n",
       " 'param bool param str str str str path the',\n",
       " 'set the visibility of the spacing for the dock',\n",
       " 'build a dictionary of combinations of readers to be',\n",
       " 'test for bug from bug and jira ticket cassandra',\n",
       " 'v1podspec a model defined in openapi',\n",
       " 'test the linesegement2d subdivide methods',\n",
       " 'test that capillary shooting in giving the unread',\n",
       " 'test the basics of normal values',\n",
       " 'tests the logoff tagging rule',\n",
       " 'return the number of layers of the jobs',\n",
       " 'test that the test hashes is correctly t correctly',\n",
       " 'return the leading monomial of f from sympy import',\n",
       " 'build a dictionary of gocdb and gives the data',\n",
       " 'return the value of the given position in the',\n",
       " 'get a list of radiance files in the tooltip',\n",
       " 'test ability to ensure that capillary serially is thrown',\n",
       " 'create a new presoview leave curviews unset msrestazure azure',\n",
       " 'test the calculation of the network reset test method',\n",
       " 'get the given data from the file with a',\n",
       " 'return the list of characters that are not present',\n",
       " 'create a new object for a given profile object',\n",
       " 'create a list of beams from a list of',\n",
       " 'get the current data from the current state',\n",
       " 'this function is aimed to decode a dateline with',\n",
       " 'returns the unaltered replaced between a dns',\n",
       " 'build a new network with a given bucket param',\n",
       " 'compute the logistic xrf image with a given image',\n",
       " 'test that the feedstock request is created for the',\n",
       " 'returns the leading monomial of f in sympy import',\n",
       " 'test that the method is valid and loading and',\n",
       " 'return the leading distance for the moment of gaussian',\n",
       " 'test that the work of the tick network test',\n",
       " 'test that the main method is correctly with a',\n",
       " 'test that we can add a validationerror if the',\n",
       " 'return a list of jobs and processes them',\n",
       " 'this function is aimed to create a optimize with',\n",
       " 'sends a request for gssapi and put bricks param',\n",
       " 'get a list of radiance of beams together and',\n",
       " 'return the unaltered transformation matrix from sympy import sympy',\n",
       " 'estimation of height of the derivative of zeros in',\n",
       " 'return the number of items in the given task',\n",
       " 'the shap model has been maintained and supplier trust',\n",
       " 'set the current state of the model',\n",
       " 'test the kgtk compact processor',\n",
       " 'create a new mediaitem of the taxlot',\n",
       " 'returns the corresponding job for the given task type',\n",
       " 'return the current state',\n",
       " 'create a new network with a list of participants',\n",
       " 'plots the density of states in the heterostructure',\n",
       " 'return the list of occupied readers',\n",
       " 'set the noise model',\n",
       " 'returns the value of the given type',\n",
       " 'client user rucio download files',\n",
       " ...]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments generated!\n"
     ]
    }
   ],
   "source": [
    "model.apply('demo.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "comgen2_25.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
